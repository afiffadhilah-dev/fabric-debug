{
  "candidate": "created_at=datetime.datetime(2026, 1, 12, 1, 15, 10, 536301) id='0c6dec64-5292-4293-859f-700411c57e6c' name='Miguel Santos'",
  "skills": [
    {
      "id": 46,
      "name": "python",
      "meaningfulness_score": "High",
      "confidence": "High (Python is fundamental in many IT roles, and evidence of proficiency is clear)",
      "created_at": "2026-01-12 05:09:43.675569",
      "dimensions": [
        {
          "id": 271,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.739122"
        },
        {
          "id": 272,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-12 05:09:43.739122"
        },
        {
          "id": 273,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.739122"
        },
        {
          "id": 274,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.739122"
        },
        {
          "id": 275,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.739122"
        },
        {
          "id": 276,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.739122"
        }
      ],
      "evidence": [
        {
          "id": 106,
          "attribute": null,
          "content": "Languages: Python, SQL",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-12 05:09:43.739122"
        }
      ]
    },
    {
      "id": 47,
      "name": "SQL",
      "meaningfulness_score": "High",
      "confidence": "High (explicit mention of SQL demonstrates familiarity and likely practical experience)",
      "created_at": "2026-01-12 05:09:43.739645",
      "dimensions": [
        {
          "id": 277,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.758953"
        },
        {
          "id": 278,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-12 05:09:43.758953"
        },
        {
          "id": 279,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.758953"
        },
        {
          "id": 280,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.758953"
        },
        {
          "id": 281,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.758953"
        },
        {
          "id": 282,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.758953"
        }
      ],
      "evidence": [
        {
          "id": 107,
          "attribute": null,
          "content": "Languages: Python, SQL",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-12 05:09:43.759510"
        }
      ]
    },
    {
      "id": 48,
      "name": "Apache Airflow",
      "meaningfulness_score": "High",
      "confidence": "High (multiple tools listed demonstrate practical experience and understanding of workflow orchestration)",
      "created_at": "2026-01-12 05:09:43.759510",
      "dimensions": [
        {
          "id": 283,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.766067"
        },
        {
          "id": 284,
          "dimension": "depth",
          "value": "integrated with Spark and dbt",
          "created_at": "2026-01-12 05:09:43.766067"
        },
        {
          "id": 285,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.766067"
        },
        {
          "id": 286,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.766067"
        },
        {
          "id": 287,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.766067"
        },
        {
          "id": 288,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.766724"
        }
      ],
      "evidence": [
        {
          "id": 108,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow, Spark, dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-12 05:09:43.766724"
        }
      ]
    },
    {
      "id": 49,
      "name": "spark",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples of designing Spark pipelines and running jobs demonstrate practical expertise)",
      "created_at": "2026-01-12 05:09:43.766724",
      "dimensions": [
        {
          "id": 289,
          "dimension": "duration",
          "value": "2026-01-12",
          "created_at": "2026-01-12 05:09:43.771669"
        },
        {
          "id": 290,
          "dimension": "depth",
          "value": "designed pipelines and models",
          "created_at": "2026-01-12 05:09:43.771669"
        },
        {
          "id": 291,
          "dimension": "autonomy",
          "value": "designed pipelines independently",
          "created_at": "2026-01-12 05:09:43.772193"
        },
        {
          "id": 292,
          "dimension": "scale",
          "value": "batch and streaming pipelines",
          "created_at": "2026-01-12 05:09:43.772193"
        },
        {
          "id": 293,
          "dimension": "constraint",
          "value": "None specified",
          "created_at": "2026-01-12 05:09:43.772193"
        },
        {
          "id": 294,
          "dimension": "production",
          "value": "used in production",
          "created_at": "2026-01-12 05:09:43.772193"
        }
      ],
      "evidence": [
        {
          "id": 109,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow, Spark, dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-12 05:09:43.772193"
        },
        {
          "id": 111,
          "attribute": null,
          "content": "I designed batch and streaming pipelines using Spark and Airflow, and built data models with dbt so analysts could trust the data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:19:40.564871",
          "created_at": "2026-01-12 05:09:43.772727"
        },
        {
          "id": 110,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-12 05:09:43.772727"
        }
      ]
    },
    {
      "id": 50,
      "name": "dbt",
      "meaningfulness_score": "High",
      "confidence": "High (specific example demonstrates understanding beyond surface level)",
      "created_at": "2026-01-12 05:09:43.772727",
      "dimensions": [
        {
          "id": 295,
          "dimension": "duration",
          "value": "ongoing experience",
          "created_at": "2026-01-12 05:09:43.780406"
        },
        {
          "id": 296,
          "dimension": "depth",
          "value": "built data models",
          "created_at": "2026-01-12 05:09:43.780936"
        },
        {
          "id": 297,
          "dimension": "autonomy",
          "value": "designed pipelines independently",
          "created_at": "2026-01-12 05:09:43.780936"
        },
        {
          "id": 298,
          "dimension": "scale",
          "value": "data pipeline scope",
          "created_at": "2026-01-12 05:09:43.780936"
        },
        {
          "id": 299,
          "dimension": "constraint",
          "value": "trust in data",
          "created_at": "2026-01-12 05:09:43.780936"
        },
        {
          "id": 300,
          "dimension": "production",
          "value": "used in analytics",
          "created_at": "2026-01-12 05:09:43.780936"
        }
      ],
      "evidence": [
        {
          "id": 113,
          "attribute": null,
          "content": "I designed batch and streaming pipelines using Spark and Airflow, and built data models with dbt so analysts could trust the data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:19:40.564871",
          "created_at": "2026-01-12 05:09:43.780936"
        },
        {
          "id": 112,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow, Spark, dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-12 05:09:43.780936"
        }
      ]
    },
    {
      "id": 51,
      "name": "postgresql",
      "meaningfulness_score": "High",
      "confidence": "High (candidate has demonstrated experience with PostgreSQL among other data stores, indicating solid familiarity)",
      "created_at": "2026-01-12 05:09:43.780936",
      "dimensions": [
        {
          "id": 301,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.787509"
        },
        {
          "id": 302,
          "dimension": "depth",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.788127"
        },
        {
          "id": 303,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.788127"
        },
        {
          "id": 304,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.788127"
        },
        {
          "id": 305,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.788127"
        },
        {
          "id": 306,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.788127"
        }
      ],
      "evidence": [
        {
          "id": 114,
          "attribute": null,
          "content": "Datastores: PostgreSQL, Snowflake, S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-12 05:09:43.788127"
        }
      ]
    },
    {
      "id": 52,
      "name": "Snowflake",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples demonstrate practical experience with Snowflake in data storage and deployment pipelines)",
      "created_at": "2026-01-12 05:09:43.788127",
      "dimensions": [
        {
          "id": 307,
          "dimension": "duration",
          "value": "used in 2026",
          "created_at": "2026-01-12 05:09:43.793128"
        },
        {
          "id": 308,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-12 05:09:43.793128"
        },
        {
          "id": 309,
          "dimension": "autonomy",
          "value": "collaborative deployment",
          "created_at": "2026-01-12 05:09:43.793128"
        },
        {
          "id": 310,
          "dimension": "scale",
          "value": "multiple datastores",
          "created_at": "2026-01-12 05:09:43.793651"
        },
        {
          "id": 311,
          "dimension": "constraint",
          "value": "pipeline deployment challenges",
          "created_at": "2026-01-12 05:09:43.793651"
        },
        {
          "id": 312,
          "dimension": "production",
          "value": "deployed in production",
          "created_at": "2026-01-12 05:09:43.793651"
        }
      ],
      "evidence": [
        {
          "id": 115,
          "attribute": null,
          "content": "Datastores: PostgreSQL, Snowflake, S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-12 05:09:43.793651"
        },
        {
          "id": 116,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-12 05:09:43.793651"
        }
      ]
    },
    {
      "id": 53,
      "name": "aws",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples demonstrate practical experience with AWS data storage and deployment pipelines)",
      "created_at": "2026-01-12 05:09:43.793651",
      "dimensions": [
        {
          "id": 313,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.801533"
        },
        {
          "id": 314,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-12 05:09:43.801533"
        },
        {
          "id": 315,
          "dimension": "autonomy",
          "value": "collaborative work",
          "created_at": "2026-01-12 05:09:43.801533"
        },
        {
          "id": 316,
          "dimension": "scale",
          "value": "multiple datastores",
          "created_at": "2026-01-12 05:09:43.802050"
        },
        {
          "id": 317,
          "dimension": "constraint",
          "value": "deployment pipeline setup",
          "created_at": "2026-01-12 05:09:43.802050"
        },
        {
          "id": 318,
          "dimension": "production",
          "value": "deployed with GitHub Actions",
          "created_at": "2026-01-12 05:09:43.802050"
        }
      ],
      "evidence": [
        {
          "id": 118,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-12 05:09:43.802050"
        },
        {
          "id": 117,
          "attribute": null,
          "content": "Datastores: PostgreSQL, Snowflake, S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-12 05:09:43.802050"
        }
      ]
    },
    {
      "id": 54,
      "name": "docker",
      "meaningfulness_score": "High",
      "confidence": "High (evidence shows practical experience with Docker in a relevant context)",
      "created_at": "2026-01-12 05:09:43.802587",
      "dimensions": [
        {
          "id": 319,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.809015"
        },
        {
          "id": 320,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-12 05:09:43.809539"
        },
        {
          "id": 321,
          "dimension": "autonomy",
          "value": "collaborative work",
          "created_at": "2026-01-12 05:09:43.809539"
        },
        {
          "id": 322,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.809539"
        },
        {
          "id": 323,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.809539"
        },
        {
          "id": 324,
          "dimension": "production",
          "value": "deployed in production",
          "created_at": "2026-01-12 05:09:43.809539"
        }
      ],
      "evidence": [
        {
          "id": 119,
          "attribute": null,
          "content": "Infrastructure: Docker, Kubernetes, GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-12 05:09:43.810073"
        }
      ]
    },
    {
      "id": 55,
      "name": "kubernetes",
      "meaningfulness_score": "High",
      "confidence": "High (clear evidence of deploying and managing containerized workloads in Kubernetes demonstrates practical proficiency)",
      "created_at": "2026-01-12 05:09:43.810073",
      "dimensions": [
        {
          "id": 325,
          "dimension": "duration",
          "value": "since 2026",
          "created_at": "2026-01-12 05:09:43.815917"
        },
        {
          "id": 326,
          "dimension": "depth",
          "value": "working with Kubernetes",
          "created_at": "2026-01-12 05:09:43.815917"
        },
        {
          "id": 327,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.815917"
        },
        {
          "id": 328,
          "dimension": "scale",
          "value": "Airflow and Spark jobs",
          "created_at": "2026-01-12 05:09:43.815917"
        },
        {
          "id": 329,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.815917"
        },
        {
          "id": 330,
          "dimension": "production",
          "value": "used in production",
          "created_at": "2026-01-12 05:09:43.815917"
        }
      ],
      "evidence": [
        {
          "id": 120,
          "attribute": null,
          "content": "Infrastructure: Docker, Kubernetes, GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-12 05:09:43.816439"
        },
        {
          "id": 121,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-12 05:09:43.816439"
        }
      ]
    },
    {
      "id": 56,
      "name": "ci/cd",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples demonstrate practical application of CI/CD tools in real projects)",
      "created_at": "2026-01-12 05:09:43.816439",
      "dimensions": [
        {
          "id": 331,
          "dimension": "duration",
          "value": "ongoing experience",
          "created_at": "2026-01-12 05:09:43.821847"
        },
        {
          "id": 332,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-12 05:09:43.821847"
        },
        {
          "id": 333,
          "dimension": "autonomy",
          "value": "used GitHub Actions",
          "created_at": "2026-01-12 05:09:43.821847"
        },
        {
          "id": 334,
          "dimension": "scale",
          "value": "multiple deployment targets",
          "created_at": "2026-01-12 05:09:43.821847"
        },
        {
          "id": 335,
          "dimension": "constraint",
          "value": "resource limits unspecified",
          "created_at": "2026-01-12 05:09:43.821847"
        },
        {
          "id": 336,
          "dimension": "production",
          "value": "pipeline deployed",
          "created_at": "2026-01-12 05:09:43.821847"
        }
      ],
      "evidence": [
        {
          "id": 122,
          "attribute": null,
          "content": "Infrastructure: Docker, Kubernetes, GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-12 05:09:43.821847"
        },
        {
          "id": 123,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-12 05:09:43.821847"
        }
      ]
    },
    {
      "id": 57,
      "name": "Airflow",
      "meaningfulness_score": "High",
      "confidence": "High (demonstrates practical experience with deploying Airflow in a containerized environment)",
      "created_at": "2026-01-12 05:09:43.822394",
      "dimensions": [
        {
          "id": 337,
          "dimension": "duration",
          "value": "recent experience",
          "created_at": "2026-01-12 05:09:43.826606"
        },
        {
          "id": 338,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-12 05:09:43.826606"
        },
        {
          "id": 339,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.826606"
        },
        {
          "id": 340,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.826606"
        },
        {
          "id": 341,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.827134"
        },
        {
          "id": 342,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-12 05:09:43.827134"
        }
      ],
      "evidence": [
        {
          "id": 124,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-12 05:09:43.827134"
        }
      ]
    },
    {
      "id": 58,
      "name": "python",
      "meaningfulness_score": "High",
      "confidence": "High (direct evidence of Python language proficiency confirms genuine skill)",
      "created_at": "2026-01-13 01:04:56.969562",
      "dimensions": [
        {
          "id": 343,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.029280"
        },
        {
          "id": 344,
          "dimension": "depth",
          "value": "basic scripting",
          "created_at": "2026-01-13 01:04:57.029806"
        },
        {
          "id": 345,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.029806"
        },
        {
          "id": 346,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.029806"
        },
        {
          "id": 347,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.029806"
        },
        {
          "id": 348,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.029806"
        }
      ],
      "evidence": [
        {
          "id": 134,
          "attribute": null,
          "content": "Languages: Python",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 01:04:57.030340"
        }
      ]
    },
    {
      "id": 59,
      "name": "SQL",
      "meaningfulness_score": "High",
      "confidence": "High (explicit mention of SQL language demonstrates familiarity and likely practical ability)",
      "created_at": "2026-01-13 01:04:57.030340",
      "dimensions": [
        {
          "id": 349,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.053586"
        },
        {
          "id": 350,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-13 01:04:57.053586"
        },
        {
          "id": 351,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.053586"
        },
        {
          "id": 352,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.053586"
        },
        {
          "id": 353,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.053586"
        },
        {
          "id": 354,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.054275"
        }
      ],
      "evidence": [
        {
          "id": 135,
          "attribute": null,
          "content": "Languages: SQL",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 01:04:57.054275"
        }
      ]
    },
    {
      "id": 60,
      "name": "Apache Airflow",
      "meaningfulness_score": "High",
      "confidence": "High (explicit mention of Apache Airflow as a framework indicates direct experience)",
      "created_at": "2026-01-13 01:04:57.054275",
      "dimensions": [
        {
          "id": 355,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.061420"
        },
        {
          "id": 356,
          "dimension": "depth",
          "value": "framework expertise",
          "created_at": "2026-01-13 01:04:57.061420"
        },
        {
          "id": 357,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.061420"
        },
        {
          "id": 358,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.061420"
        },
        {
          "id": 359,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.061420"
        },
        {
          "id": 360,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.061420"
        }
      ],
      "evidence": [
        {
          "id": 136,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 01:04:57.061945"
        }
      ]
    },
    {
      "id": 61,
      "name": "spark",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples demonstrate practical application and understanding of Spark in real-world scenarios)",
      "created_at": "2026-01-13 01:04:57.061945",
      "dimensions": [
        {
          "id": 361,
          "dimension": "duration",
          "value": "multiple years of experience",
          "created_at": "2026-01-13 01:04:57.068137"
        },
        {
          "id": 362,
          "dimension": "depth",
          "value": "advanced knowledge of Spark",
          "created_at": "2026-01-13 01:04:57.068671"
        },
        {
          "id": 363,
          "dimension": "autonomy",
          "value": "designed pipelines independently",
          "created_at": "2026-01-13 01:04:57.068671"
        },
        {
          "id": 364,
          "dimension": "scale",
          "value": "batch and streaming pipelines",
          "created_at": "2026-01-13 01:04:57.068671"
        },
        {
          "id": 365,
          "dimension": "constraint",
          "value": "Kubernetes environment challenges",
          "created_at": "2026-01-13 01:04:57.068671"
        },
        {
          "id": 366,
          "dimension": "production",
          "value": "used in data pipelines",
          "created_at": "2026-01-13 01:04:57.068671"
        }
      ],
      "evidence": [
        {
          "id": 139,
          "attribute": null,
          "content": "I designed batch and streaming pipelines using Spark and Airflow, and built data models with dbt so analysts could trust the data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:19:40.564871",
          "created_at": "2026-01-13 01:04:57.068671"
        },
        {
          "id": 137,
          "attribute": null,
          "content": "Frameworks & Tools: Spark",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 01:04:57.068671"
        },
        {
          "id": 138,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 01:04:57.068671"
        }
      ]
    },
    {
      "id": 62,
      "name": "dbt",
      "meaningfulness_score": "High",
      "confidence": "High (specific example demonstrates understanding beyond surface level)",
      "created_at": "2026-01-13 01:04:57.069368",
      "dimensions": [
        {
          "id": 367,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.078084"
        },
        {
          "id": 368,
          "dimension": "depth",
          "value": "data modeling expertise",
          "created_at": "2026-01-13 01:04:57.078084"
        },
        {
          "id": 369,
          "dimension": "autonomy",
          "value": "independent development",
          "created_at": "2026-01-13 01:04:57.078084"
        },
        {
          "id": 370,
          "dimension": "scale",
          "value": "data models for analysts",
          "created_at": "2026-01-13 01:04:57.078084"
        },
        {
          "id": 371,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.078084"
        },
        {
          "id": 372,
          "dimension": "production",
          "value": "used by analysts",
          "created_at": "2026-01-13 01:04:57.078734"
        }
      ],
      "evidence": [
        {
          "id": 141,
          "attribute": null,
          "content": "I designed batch and streaming pipelines using Spark and Airflow, and built data models with dbt so analysts could trust the data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:19:40.564871",
          "created_at": "2026-01-13 01:04:57.078734"
        },
        {
          "id": 140,
          "attribute": null,
          "content": "Frameworks & Tools: dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 01:04:57.078734"
        }
      ]
    },
    {
      "id": 63,
      "name": "postgresql",
      "meaningfulness_score": "High",
      "confidence": "High (database management is fundamental in many IT roles; evidence of PostgreSQL usage confirms practical knowledge)",
      "created_at": "2026-01-13 01:04:57.078734",
      "dimensions": [
        {
          "id": 373,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.086562"
        },
        {
          "id": 374,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-13 01:04:57.086562"
        },
        {
          "id": 375,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.086562"
        },
        {
          "id": 376,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.086562"
        },
        {
          "id": 377,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.086562"
        },
        {
          "id": 378,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.086562"
        }
      ],
      "evidence": [
        {
          "id": 142,
          "attribute": null,
          "content": "Datastores: PostgreSQL",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 01:04:57.086562"
        }
      ]
    },
    {
      "id": 64,
      "name": "Snowflake",
      "meaningfulness_score": "High",
      "confidence": "High (extensive mention of Snowflake in data storage and deployment processes indicates strong familiarity)",
      "created_at": "2026-01-13 01:04:57.086562",
      "dimensions": [
        {
          "id": 379,
          "dimension": "duration",
          "value": "recently started using",
          "created_at": "2026-01-13 01:04:57.094412"
        },
        {
          "id": 380,
          "dimension": "depth",
          "value": "basic knowledge of Snowflake",
          "created_at": "2026-01-13 01:04:57.094412"
        },
        {
          "id": 381,
          "dimension": "autonomy",
          "value": "collaborative deployment",
          "created_at": "2026-01-13 01:04:57.094412"
        },
        {
          "id": 382,
          "dimension": "scale",
          "value": "Data stored in Snowflake and S3",
          "created_at": "2026-01-13 01:04:57.094412"
        },
        {
          "id": 383,
          "dimension": "constraint",
          "value": "none specified",
          "created_at": "2026-01-13 01:04:57.094412"
        },
        {
          "id": 384,
          "dimension": "production",
          "value": "not explicitly stated",
          "created_at": "2026-01-13 01:04:57.094412"
        }
      ],
      "evidence": [
        {
          "id": 144,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 01:04:57.094412"
        },
        {
          "id": 143,
          "attribute": null,
          "content": "Datastores: Snowflake",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 01:04:57.094412"
        }
      ]
    },
    {
      "id": 65,
      "name": "aws",
      "meaningfulness_score": "High",
      "confidence": "Medium-High (evidence shows practical use of AWS services in data storage and deployment pipelines)",
      "created_at": "2026-01-13 01:04:57.095086",
      "dimensions": [
        {
          "id": 385,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.101612"
        },
        {
          "id": 386,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-13 01:04:57.102146"
        },
        {
          "id": 387,
          "dimension": "autonomy",
          "value": "collaborative work",
          "created_at": "2026-01-13 01:04:57.102146"
        },
        {
          "id": 388,
          "dimension": "scale",
          "value": "small data scope",
          "created_at": "2026-01-13 01:04:57.102146"
        },
        {
          "id": 389,
          "dimension": "constraint",
          "value": "none specified",
          "created_at": "2026-01-13 01:04:57.102146"
        },
        {
          "id": 390,
          "dimension": "production",
          "value": "not specified",
          "created_at": "2026-01-13 01:04:57.102146"
        }
      ],
      "evidence": [
        {
          "id": 145,
          "attribute": null,
          "content": "Datastores: S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 01:04:57.102146"
        },
        {
          "id": 146,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 01:04:57.102782"
        }
      ]
    },
    {
      "id": 66,
      "name": "docker",
      "meaningfulness_score": "High",
      "confidence": "High (evidence directly states familiarity with Docker in infrastructure context)",
      "created_at": "2026-01-13 01:04:57.102782",
      "dimensions": [
        {
          "id": 391,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.108111"
        },
        {
          "id": 392,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-13 01:04:57.108654"
        },
        {
          "id": 393,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.108654"
        },
        {
          "id": 394,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.108654"
        },
        {
          "id": 395,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.108654"
        },
        {
          "id": 396,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.108654"
        }
      ],
      "evidence": [
        {
          "id": 147,
          "attribute": null,
          "content": "Infrastructure: Docker",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 01:04:57.108654"
        }
      ]
    },
    {
      "id": 67,
      "name": "kubernetes",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples of running Airflow and Spark jobs demonstrate practical experience)",
      "created_at": "2026-01-13 01:04:57.109188",
      "dimensions": [
        {
          "id": 397,
          "dimension": "duration",
          "value": "multiple years",
          "created_at": "2026-01-13 01:04:57.195913"
        },
        {
          "id": 398,
          "dimension": "depth",
          "value": "advanced knowledge",
          "created_at": "2026-01-13 01:04:57.195913"
        },
        {
          "id": 399,
          "dimension": "autonomy",
          "value": "independent work",
          "created_at": "2026-01-13 01:04:57.197007"
        },
        {
          "id": 400,
          "dimension": "scale",
          "value": "running Airflow and Spark jobs",
          "created_at": "2026-01-13 01:04:57.197007"
        },
        {
          "id": 401,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.197007"
        },
        {
          "id": 402,
          "dimension": "production",
          "value": "deployed in production",
          "created_at": "2026-01-13 01:04:57.197007"
        }
      ],
      "evidence": [
        {
          "id": 148,
          "attribute": null,
          "content": "Infrastructure: Kubernetes",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 01:04:57.197007"
        },
        {
          "id": 149,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 01:04:57.197007"
        }
      ]
    },
    {
      "id": 68,
      "name": "ci/cd",
      "meaningfulness_score": "High",
      "confidence": "High (demonstrates practical experience with CI/CD pipelines using popular tools and cloud services)",
      "created_at": "2026-01-13 01:04:57.197007",
      "dimensions": [
        {
          "id": 403,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.205345"
        },
        {
          "id": 404,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-13 01:04:57.205345"
        },
        {
          "id": 405,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.205345"
        },
        {
          "id": 406,
          "dimension": "scale",
          "value": "pipeline deployment",
          "created_at": "2026-01-13 01:04:57.205345"
        },
        {
          "id": 407,
          "dimension": "constraint",
          "value": "migration complexity",
          "created_at": "2026-01-13 01:04:57.205862"
        },
        {
          "id": 408,
          "dimension": "production",
          "value": "deployed in production",
          "created_at": "2026-01-13 01:04:57.205862"
        }
      ],
      "evidence": [
        {
          "id": 150,
          "attribute": null,
          "content": "Infrastructure: GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 01:04:57.205862"
        },
        {
          "id": 151,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 01:04:57.205862"
        }
      ]
    },
    {
      "id": 69,
      "name": "Airflow",
      "meaningfulness_score": "High",
      "confidence": "Medium-High (evidence shows practical experience in deploying Airflow in a relevant environment, but lacks details on configuration or troubleshooting)",
      "created_at": "2026-01-13 01:04:57.205862",
      "dimensions": [
        {
          "id": 409,
          "dimension": "duration",
          "value": "recently used",
          "created_at": "2026-01-13 01:04:57.218560"
        },
        {
          "id": 410,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-13 01:04:57.219097"
        },
        {
          "id": 411,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.219097"
        },
        {
          "id": 412,
          "dimension": "scale",
          "value": "Kubernetes jobs",
          "created_at": "2026-01-13 01:04:57.219097"
        },
        {
          "id": 413,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.219097"
        },
        {
          "id": 414,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 01:04:57.219639"
        }
      ],
      "evidence": [
        {
          "id": 152,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 01:04:57.219639"
        }
      ]
    },
    {
      "id": 70,
      "name": "Airflow",
      "meaningfulness_score": "High",
      "confidence": "High (demonstrates practical experience with Airflow in a relevant environment)",
      "created_at": "2026-01-13 03:43:29.150533",
      "dimensions": [
        {
          "id": 415,
          "dimension": "duration",
          "value": "recently used",
          "created_at": "2026-01-13 03:43:29.190052"
        },
        {
          "id": 416,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-13 03:43:29.190052"
        },
        {
          "id": 417,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.190052"
        },
        {
          "id": 418,
          "dimension": "scale",
          "value": "Kubernetes jobs",
          "created_at": "2026-01-13 03:43:29.190052"
        },
        {
          "id": 419,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.190052"
        },
        {
          "id": 420,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.190052"
        }
      ],
      "evidence": [
        {
          "id": 161,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 03:43:29.190052"
        }
      ]
    },
    {
      "id": 71,
      "name": "spark",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples demonstrate practical application and design experience with Spark in relevant contexts)",
      "created_at": "2026-01-13 03:43:29.190596",
      "dimensions": [
        {
          "id": 421,
          "dimension": "duration",
          "value": "recently started",
          "created_at": "2026-01-13 03:43:29.204256"
        },
        {
          "id": 422,
          "dimension": "depth",
          "value": "designed pipelines and models",
          "created_at": "2026-01-13 03:43:29.204256"
        },
        {
          "id": 423,
          "dimension": "autonomy",
          "value": "designed workflows independently",
          "created_at": "2026-01-13 03:43:29.204256"
        },
        {
          "id": 424,
          "dimension": "scale",
          "value": "used in Kubernetes environment",
          "created_at": "2026-01-13 03:43:29.204256"
        },
        {
          "id": 425,
          "dimension": "constraint",
          "value": "resource management challenges",
          "created_at": "2026-01-13 03:43:29.204256"
        },
        {
          "id": 426,
          "dimension": "production",
          "value": "used in production",
          "created_at": "2026-01-13 03:43:29.204256"
        }
      ],
      "evidence": [
        {
          "id": 162,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 03:43:29.204256"
        },
        {
          "id": 163,
          "attribute": null,
          "content": "I designed batch and streaming pipelines using Spark and Airflow, and built data models with dbt so analysts could trust the data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:19:40.564871",
          "created_at": "2026-01-13 03:43:29.204977"
        }
      ]
    },
    {
      "id": 72,
      "name": "kubernetes",
      "meaningfulness_score": "High",
      "confidence": "High (specific example demonstrates practical experience deploying complex applications in Kubernetes)",
      "created_at": "2026-01-13 03:43:29.204977",
      "dimensions": [
        {
          "id": 427,
          "dimension": "duration",
          "value": "recently started working",
          "created_at": "2026-01-13 03:43:29.212128"
        },
        {
          "id": 428,
          "dimension": "depth",
          "value": "basic knowledge of Kubernetes",
          "created_at": "2026-01-13 03:43:29.212128"
        },
        {
          "id": 429,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.212128"
        },
        {
          "id": 430,
          "dimension": "scale",
          "value": "used for job execution",
          "created_at": "2026-01-13 03:43:29.212128"
        },
        {
          "id": 431,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.212128"
        },
        {
          "id": 432,
          "dimension": "production",
          "value": "deployed in production",
          "created_at": "2026-01-13 03:43:29.212128"
        }
      ],
      "evidence": [
        {
          "id": 164,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 03:43:29.212657"
        }
      ]
    },
    {
      "id": 73,
      "name": "Snowflake",
      "meaningfulness_score": "High",
      "confidence": "Medium-High (evidence suggests practical use but limited detail on depth of expertise)",
      "created_at": "2026-01-13 03:43:29.212657",
      "dimensions": [
        {
          "id": 433,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.217931"
        },
        {
          "id": 434,
          "dimension": "depth",
          "value": "basic data storage",
          "created_at": "2026-01-13 03:43:29.217931"
        },
        {
          "id": 435,
          "dimension": "autonomy",
          "value": "collaborative deployment",
          "created_at": "2026-01-13 03:43:29.217931"
        },
        {
          "id": 436,
          "dimension": "scale",
          "value": "multi-platform storage",
          "created_at": "2026-01-13 03:43:29.217931"
        },
        {
          "id": 437,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.217931"
        },
        {
          "id": 438,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.217931"
        }
      ],
      "evidence": [
        {
          "id": 165,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 03:43:29.217931"
        }
      ]
    },
    {
      "id": 74,
      "name": "aws",
      "meaningfulness_score": "High",
      "confidence": "Medium-High (evidence directly relates to AWS storage services, indicating familiarity with cloud infrastructure)",
      "created_at": "2026-01-13 03:43:29.217931",
      "dimensions": [
        {
          "id": 439,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.223606"
        },
        {
          "id": 440,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-13 03:43:29.223606"
        },
        {
          "id": 441,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.223606"
        },
        {
          "id": 442,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.223606"
        },
        {
          "id": 443,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.223606"
        },
        {
          "id": 444,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.223606"
        }
      ],
      "evidence": [
        {
          "id": 166,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 03:43:29.223606"
        }
      ]
    },
    {
      "id": 75,
      "name": "ci/cd",
      "meaningfulness_score": "High",
      "confidence": "Medium-High (evidence of using GitHub Actions for CI/CD demonstrates practical experience, but lacks detailed implementation specifics)",
      "created_at": "2026-01-13 03:43:29.224144",
      "dimensions": [
        {
          "id": 445,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.229850"
        },
        {
          "id": 446,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-13 03:43:29.229850"
        },
        {
          "id": 447,
          "dimension": "autonomy",
          "value": "collaborative effort",
          "created_at": "2026-01-13 03:43:29.229850"
        },
        {
          "id": 448,
          "dimension": "scale",
          "value": "small data pipelines",
          "created_at": "2026-01-13 03:43:29.229850"
        },
        {
          "id": 449,
          "dimension": "constraint",
          "value": "no specific challenges",
          "created_at": "2026-01-13 03:43:29.229850"
        },
        {
          "id": 450,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.230365"
        }
      ],
      "evidence": [
        {
          "id": 167,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 03:43:29.230365"
        }
      ]
    },
    {
      "id": 76,
      "name": "dbt",
      "meaningfulness_score": "High",
      "confidence": "High (clear evidence of designing data models with dbt for analytical trust)",
      "created_at": "2026-01-13 03:43:29.230365",
      "dimensions": [
        {
          "id": 451,
          "dimension": "duration",
          "value": "unspecified duration",
          "created_at": "2026-01-13 03:43:29.235804"
        },
        {
          "id": 452,
          "dimension": "depth",
          "value": "built data models",
          "created_at": "2026-01-13 03:43:29.235804"
        },
        {
          "id": 453,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.235804"
        },
        {
          "id": 454,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.236375"
        },
        {
          "id": 455,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.236375"
        },
        {
          "id": 456,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 03:43:29.236375"
        }
      ],
      "evidence": [
        {
          "id": 168,
          "attribute": null,
          "content": "I designed batch and streaming pipelines using Spark and Airflow, and built data models with dbt so analysts could trust the data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:19:40.564871",
          "created_at": "2026-01-13 03:43:29.236375"
        }
      ]
    },
    {
      "id": 77,
      "name": "python",
      "meaningfulness_score": "High",
      "confidence": "High (well-known programming language widely used in various IT roles)",
      "created_at": "2026-01-13 04:10:16.080406",
      "dimensions": [
        {
          "id": 457,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.121814"
        },
        {
          "id": 458,
          "dimension": "depth",
          "value": "basic programming knowledge",
          "created_at": "2026-01-13 04:10:16.121814"
        },
        {
          "id": 459,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.121814"
        },
        {
          "id": 460,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.121814"
        },
        {
          "id": 461,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.122378"
        },
        {
          "id": 462,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.122378"
        }
      ],
      "evidence": [
        {
          "id": 176,
          "attribute": null,
          "content": "Languages: Python, SQL",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:10:16.122378"
        }
      ]
    },
    {
      "id": 78,
      "name": "SQL",
      "meaningfulness_score": "High",
      "confidence": "High (direct mention of SQL as a language indicates proficiency)",
      "created_at": "2026-01-13 04:10:16.122987",
      "dimensions": [
        {
          "id": 463,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.133052"
        },
        {
          "id": 464,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-13 04:10:16.133052"
        },
        {
          "id": 465,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.133052"
        },
        {
          "id": 466,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.133052"
        },
        {
          "id": 467,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.133052"
        },
        {
          "id": 468,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.133052"
        }
      ],
      "evidence": [
        {
          "id": 177,
          "attribute": null,
          "content": "Languages: Python, SQL",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:10:16.133052"
        }
      ]
    },
    {
      "id": 79,
      "name": "Apache Airflow",
      "meaningfulness_score": "High",
      "confidence": "High (candidate demonstrates specific experience with Apache Airflow in a relevant technical context)",
      "created_at": "2026-01-13 04:10:16.133052",
      "dimensions": [
        {
          "id": 469,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.141253"
        },
        {
          "id": 470,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-13 04:10:16.141253"
        },
        {
          "id": 471,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.141253"
        },
        {
          "id": 472,
          "dimension": "scale",
          "value": "enterprise scope",
          "created_at": "2026-01-13 04:10:16.141818"
        },
        {
          "id": 473,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.141818"
        },
        {
          "id": 474,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.141818"
        }
      ],
      "evidence": [
        {
          "id": 178,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow, Spark, dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:10:16.141818"
        }
      ]
    },
    {
      "id": 80,
      "name": "spark",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples demonstrate practical application and understanding of Spark in data pipelines)",
      "created_at": "2026-01-13 04:10:16.141818",
      "dimensions": [
        {
          "id": 475,
          "dimension": "duration",
          "value": "multiple years",
          "created_at": "2026-01-13 04:10:16.147249"
        },
        {
          "id": 476,
          "dimension": "depth",
          "value": "advanced knowledge",
          "created_at": "2026-01-13 04:10:16.147249"
        },
        {
          "id": 477,
          "dimension": "autonomy",
          "value": "designed pipelines independently",
          "created_at": "2026-01-13 04:10:16.148096"
        },
        {
          "id": 478,
          "dimension": "scale",
          "value": "data pipelines in Kubernetes",
          "created_at": "2026-01-13 04:10:16.148096"
        },
        {
          "id": 479,
          "dimension": "constraint",
          "value": "resource limits, performance issues",
          "created_at": "2026-01-13 04:10:16.148096"
        },
        {
          "id": 480,
          "dimension": "production",
          "value": "used in production",
          "created_at": "2026-01-13 04:10:16.148096"
        }
      ],
      "evidence": [
        {
          "id": 180,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 04:10:16.148096"
        },
        {
          "id": 179,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow, Spark, dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:10:16.148096"
        },
        {
          "id": 181,
          "attribute": null,
          "content": "I designed batch and streaming pipelines using Spark and Airflow, and built data models with dbt so analysts could trust the data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:19:40.564871",
          "created_at": "2026-01-13 04:10:16.148096"
        }
      ]
    },
    {
      "id": 81,
      "name": "dbt",
      "meaningfulness_score": "High",
      "confidence": "High (specific example demonstrates understanding beyond surface level)",
      "created_at": "2026-01-13 04:10:16.148096",
      "dimensions": [
        {
          "id": 481,
          "dimension": "duration",
          "value": "ongoing",
          "created_at": "2026-01-13 04:10:16.154956"
        },
        {
          "id": 482,
          "dimension": "depth",
          "value": "built data models",
          "created_at": "2026-01-13 04:10:16.154956"
        },
        {
          "id": 483,
          "dimension": "autonomy",
          "value": "designed pipelines independently",
          "created_at": "2026-01-13 04:10:16.155479"
        },
        {
          "id": 484,
          "dimension": "scale",
          "value": "data modeling for analysts",
          "created_at": "2026-01-13 04:10:16.155479"
        },
        {
          "id": 485,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.155479"
        },
        {
          "id": 486,
          "dimension": "production",
          "value": "used in data models",
          "created_at": "2026-01-13 04:10:16.155479"
        }
      ],
      "evidence": [
        {
          "id": 183,
          "attribute": null,
          "content": "I designed batch and streaming pipelines using Spark and Airflow, and built data models with dbt so analysts could trust the data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:19:40.564871",
          "created_at": "2026-01-13 04:10:16.155479"
        },
        {
          "id": 182,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow, Spark, dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:10:16.155479"
        }
      ]
    },
    {
      "id": 82,
      "name": "postgresql",
      "meaningfulness_score": "High",
      "confidence": "High (candidate demonstrates direct experience with PostgreSQL among multiple datastores, indicating genuine familiarity)",
      "created_at": "2026-01-13 04:10:16.156005",
      "dimensions": [
        {
          "id": 487,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.161556"
        },
        {
          "id": 488,
          "dimension": "depth",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.161556"
        },
        {
          "id": 489,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.162190"
        },
        {
          "id": 490,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.162190"
        },
        {
          "id": 491,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.162190"
        },
        {
          "id": 492,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.162190"
        }
      ],
      "evidence": [
        {
          "id": 184,
          "attribute": null,
          "content": "Datastores: PostgreSQL, Snowflake, S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:10:16.162190"
        }
      ]
    },
    {
      "id": 83,
      "name": "Snowflake",
      "meaningfulness_score": "High",
      "confidence": "High (specific example demonstrates understanding beyond surface level)",
      "created_at": "2026-01-13 04:10:16.162190",
      "dimensions": [
        {
          "id": 493,
          "dimension": "duration",
          "value": "used in recent projects",
          "created_at": "2026-01-13 04:10:16.168213"
        },
        {
          "id": 494,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-13 04:10:16.168213"
        },
        {
          "id": 495,
          "dimension": "autonomy",
          "value": "collaborative work",
          "created_at": "2026-01-13 04:10:16.168213"
        },
        {
          "id": 496,
          "dimension": "scale",
          "value": "multiple data sources",
          "created_at": "2026-01-13 04:10:16.168213"
        },
        {
          "id": 497,
          "dimension": "constraint",
          "value": "deployment automation",
          "created_at": "2026-01-13 04:10:16.168213"
        },
        {
          "id": 498,
          "dimension": "production",
          "value": "pipeline deployed",
          "created_at": "2026-01-13 04:10:16.168213"
        }
      ],
      "evidence": [
        {
          "id": 186,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 04:10:16.168826"
        },
        {
          "id": 185,
          "attribute": null,
          "content": "Datastores: PostgreSQL, Snowflake, S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:10:16.168826"
        }
      ]
    },
    {
      "id": 84,
      "name": "aws",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples demonstrate practical experience with AWS storage services and deployment processes)",
      "created_at": "2026-01-13 04:10:16.168826",
      "dimensions": [
        {
          "id": 499,
          "dimension": "duration",
          "value": "recent work",
          "created_at": "2026-01-13 04:10:16.175206"
        },
        {
          "id": 500,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-13 04:10:16.175740"
        },
        {
          "id": 501,
          "dimension": "autonomy",
          "value": "collaborative effort",
          "created_at": "2026-01-13 04:10:16.175740"
        },
        {
          "id": 502,
          "dimension": "scale",
          "value": "multi-datastore management",
          "created_at": "2026-01-13 04:10:16.175740"
        },
        {
          "id": 503,
          "dimension": "constraint",
          "value": "deployment automation",
          "created_at": "2026-01-13 04:10:16.175740"
        },
        {
          "id": 504,
          "dimension": "production",
          "value": "pipeline deployed",
          "created_at": "2026-01-13 04:10:16.175740"
        }
      ],
      "evidence": [
        {
          "id": 187,
          "attribute": null,
          "content": "Datastores: PostgreSQL, Snowflake, S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:10:16.175740"
        },
        {
          "id": 188,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 04:10:16.176294"
        }
      ]
    },
    {
      "id": 85,
      "name": "docker",
      "meaningfulness_score": "High",
      "confidence": "High (experience with Docker and related tools suggests strong proficiency)",
      "created_at": "2026-01-13 04:10:16.176294",
      "dimensions": [
        {
          "id": 505,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.182311"
        },
        {
          "id": 506,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-13 04:10:16.182311"
        },
        {
          "id": 507,
          "dimension": "autonomy",
          "value": "collaborative work",
          "created_at": "2026-01-13 04:10:16.182311"
        },
        {
          "id": 508,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.182311"
        },
        {
          "id": 509,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.182311"
        },
        {
          "id": 510,
          "dimension": "production",
          "value": "deployed in production",
          "created_at": "2026-01-13 04:10:16.182311"
        }
      ],
      "evidence": [
        {
          "id": 189,
          "attribute": null,
          "content": "Infrastructure: Docker, Kubernetes, GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:10:16.182311"
        }
      ]
    },
    {
      "id": 86,
      "name": "kubernetes",
      "meaningfulness_score": "High",
      "confidence": "High (specific example demonstrates ability to deploy and manage complex workloads in Kubernetes)",
      "created_at": "2026-01-13 04:10:16.182311",
      "dimensions": [
        {
          "id": 511,
          "dimension": "duration",
          "value": "used since 2026",
          "created_at": "2026-01-13 04:10:16.189946"
        },
        {
          "id": 512,
          "dimension": "depth",
          "value": "worked with Kubernetes",
          "created_at": "2026-01-13 04:10:16.189946"
        },
        {
          "id": 513,
          "dimension": "autonomy",
          "value": "collaborative environment",
          "created_at": "2026-01-13 04:10:16.189946"
        },
        {
          "id": 514,
          "dimension": "scale",
          "value": "multiple job types",
          "created_at": "2026-01-13 04:10:16.189946"
        },
        {
          "id": 515,
          "dimension": "constraint",
          "value": "resource management issues",
          "created_at": "2026-01-13 04:10:16.189946"
        },
        {
          "id": 516,
          "dimension": "production",
          "value": "deployed in production",
          "created_at": "2026-01-13 04:10:16.190479"
        }
      ],
      "evidence": [
        {
          "id": 190,
          "attribute": null,
          "content": "Infrastructure: Docker, Kubernetes, GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:10:16.190479"
        },
        {
          "id": 191,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 04:10:16.190479"
        }
      ]
    },
    {
      "id": 87,
      "name": "ci/cd",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples demonstrate a solid understanding of CI/CD practices and tools)",
      "created_at": "2026-01-13 04:10:16.190479",
      "dimensions": [
        {
          "id": 517,
          "dimension": "duration",
          "value": "recent",
          "created_at": "2026-01-13 04:10:16.196449"
        },
        {
          "id": 518,
          "dimension": "depth",
          "value": "intermediate",
          "created_at": "2026-01-13 04:10:16.196449"
        },
        {
          "id": 519,
          "dimension": "autonomy",
          "value": "used GitHub Actions",
          "created_at": "2026-01-13 04:10:16.196449"
        },
        {
          "id": 520,
          "dimension": "scale",
          "value": "multiple services",
          "created_at": "2026-01-13 04:10:16.196449"
        },
        {
          "id": 521,
          "dimension": "constraint",
          "value": "deployment complexity",
          "created_at": "2026-01-13 04:10:16.196449"
        },
        {
          "id": 522,
          "dimension": "production",
          "value": "deployed pipeline",
          "created_at": "2026-01-13 04:10:16.196449"
        }
      ],
      "evidence": [
        {
          "id": 192,
          "attribute": null,
          "content": "Infrastructure: Docker, Kubernetes, GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:10:16.197127"
        },
        {
          "id": 193,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 04:10:16.197127"
        }
      ]
    },
    {
      "id": 88,
      "name": "Airflow",
      "meaningfulness_score": "High",
      "confidence": "Medium-High (demonstrates practical experience with Airflow in containerized environments)",
      "created_at": "2026-01-13 04:10:16.197127",
      "dimensions": [
        {
          "id": 523,
          "dimension": "duration",
          "value": "recent work",
          "created_at": "2026-01-13 04:10:16.202950"
        },
        {
          "id": 524,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-13 04:10:16.202950"
        },
        {
          "id": 525,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.202950"
        },
        {
          "id": 526,
          "dimension": "scale",
          "value": "Kubernetes environment",
          "created_at": "2026-01-13 04:10:16.202950"
        },
        {
          "id": 527,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 04:10:16.202950"
        },
        {
          "id": 528,
          "dimension": "production",
          "value": "deployed in production",
          "created_at": "2026-01-13 04:10:16.202950"
        }
      ],
      "evidence": [
        {
          "id": 194,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 04:10:16.203484"
        }
      ]
    },
    {
      "id": 89,
      "name": "python",
      "meaningfulness_score": "High",
      "confidence": "High (Python is fundamental for many roles and the evidence confirms proficiency)",
      "created_at": "2026-01-13 04:57:01.061044",
      "dimensions": [
        {
          "id": 529,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.143369"
        },
        {
          "id": 530,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-13 04:57:01.143889"
        },
        {
          "id": 531,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.143889"
        },
        {
          "id": 532,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.143889"
        },
        {
          "id": 533,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.143889"
        },
        {
          "id": 534,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.143889"
        }
      ],
      "evidence": [
        {
          "id": 204,
          "attribute": null,
          "content": "Languages: Python, SQL",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:57:01.144397"
        }
      ]
    },
    {
      "id": 90,
      "name": "SQL",
      "meaningfulness_score": "High",
      "confidence": "High (direct mention of SQL as a language indicates genuine skill)",
      "created_at": "2026-01-13 04:57:01.144397",
      "dimensions": [
        {
          "id": 535,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.167271"
        },
        {
          "id": 536,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-13 04:57:01.167271"
        },
        {
          "id": 537,
          "dimension": "autonomy",
          "value": "collaborative work",
          "created_at": "2026-01-13 04:57:01.167271"
        },
        {
          "id": 538,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.167271"
        },
        {
          "id": 539,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.168281"
        },
        {
          "id": 540,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.168281"
        }
      ],
      "evidence": [
        {
          "id": 205,
          "attribute": null,
          "content": "Languages: Python, SQL",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:57:01.168281"
        }
      ]
    },
    {
      "id": 91,
      "name": "Apache Airflow",
      "meaningfulness_score": "High",
      "confidence": "High (multiple mentions in relevant contexts indicate strong familiarity)",
      "created_at": "2026-01-13 04:57:01.168281",
      "dimensions": [
        {
          "id": 541,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.177520"
        },
        {
          "id": 542,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-13 04:57:01.177520"
        },
        {
          "id": 543,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.177520"
        },
        {
          "id": 544,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.177520"
        },
        {
          "id": 545,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.178275"
        },
        {
          "id": 546,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.178275"
        }
      ],
      "evidence": [
        {
          "id": 206,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow, Spark, dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:57:01.178275"
        }
      ]
    },
    {
      "id": 92,
      "name": "spark",
      "meaningfulness_score": "High",
      "confidence": "High (multiple specific examples demonstrate practical experience with Spark in relevant tasks)",
      "created_at": "2026-01-13 04:57:01.179215",
      "dimensions": [
        {
          "id": 547,
          "dimension": "duration",
          "value": "multiple years of experience",
          "created_at": "2026-01-13 04:57:01.185692"
        },
        {
          "id": 548,
          "dimension": "depth",
          "value": "designed batch and streaming pipelines",
          "created_at": "2026-01-13 04:57:01.186220"
        },
        {
          "id": 549,
          "dimension": "autonomy",
          "value": "designed pipelines independently",
          "created_at": "2026-01-13 04:57:01.186220"
        },
        {
          "id": 550,
          "dimension": "scale",
          "value": "used in Kubernetes environment",
          "created_at": "2026-01-13 04:57:01.186220"
        },
        {
          "id": 551,
          "dimension": "constraint",
          "value": "resource limits not specified",
          "created_at": "2026-01-13 04:57:01.186220"
        },
        {
          "id": 552,
          "dimension": "production",
          "value": "used in live system",
          "created_at": "2026-01-13 04:57:01.186220"
        }
      ],
      "evidence": [
        {
          "id": 207,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow, Spark, dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:57:01.186220"
        },
        {
          "id": 208,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 04:57:01.186750"
        },
        {
          "id": 209,
          "attribute": null,
          "content": "I designed batch and streaming pipelines using Spark and Airflow, and built data models with dbt so analysts could trust the data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:19:40.564871",
          "created_at": "2026-01-13 04:57:01.186750"
        }
      ]
    },
    {
      "id": 93,
      "name": "dbt",
      "meaningfulness_score": "High",
      "confidence": "High (specific example demonstrates understanding beyond surface level)",
      "created_at": "2026-01-13 04:57:01.186750",
      "dimensions": [
        {
          "id": 553,
          "dimension": "duration",
          "value": "Ongoing since 2026",
          "created_at": "2026-01-13 04:57:01.213050"
        },
        {
          "id": 554,
          "dimension": "depth",
          "value": "Built data models with dbt",
          "created_at": "2026-01-13 04:57:01.213050"
        },
        {
          "id": 555,
          "dimension": "autonomy",
          "value": "Designed pipelines independently",
          "created_at": "2026-01-13 04:57:01.213050"
        },
        {
          "id": 556,
          "dimension": "scale",
          "value": "Data modeling for analysts",
          "created_at": "2026-01-13 04:57:01.213050"
        },
        {
          "id": 557,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.213050"
        },
        {
          "id": 558,
          "dimension": "production",
          "value": "Data trusted by analysts",
          "created_at": "2026-01-13 04:57:01.213050"
        }
      ],
      "evidence": [
        {
          "id": 211,
          "attribute": null,
          "content": "I designed batch and streaming pipelines using Spark and Airflow, and built data models with dbt so analysts could trust the data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:19:40.564871",
          "created_at": "2026-01-13 04:57:01.213581"
        },
        {
          "id": 210,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow, Spark, dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:57:01.213581"
        }
      ]
    },
    {
      "id": 94,
      "name": "postgresql",
      "meaningfulness_score": "High",
      "confidence": "High (candidate demonstrates specific experience with PostgreSQL among other datastores)",
      "created_at": "2026-01-13 04:57:01.213581",
      "dimensions": [
        {
          "id": 559,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.220594"
        },
        {
          "id": 560,
          "dimension": "depth",
          "value": "database expertise",
          "created_at": "2026-01-13 04:57:01.221140"
        },
        {
          "id": 561,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.221140"
        },
        {
          "id": 562,
          "dimension": "scale",
          "value": "multiple datastores",
          "created_at": "2026-01-13 04:57:01.221140"
        },
        {
          "id": 563,
          "dimension": "constraint",
          "value": "migration complexity",
          "created_at": "2026-01-13 04:57:01.221140"
        },
        {
          "id": 564,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.221140"
        }
      ],
      "evidence": [
        {
          "id": 212,
          "attribute": null,
          "content": "Datastores: PostgreSQL, Snowflake, S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:57:01.221140"
        }
      ]
    },
    {
      "id": 95,
      "name": "Snowflake",
      "meaningfulness_score": "High",
      "confidence": "High (multiple examples of working with Snowflake in different contexts demonstrate solid familiarity)",
      "created_at": "2026-01-13 04:57:01.221688",
      "dimensions": [
        {
          "id": 565,
          "dimension": "duration",
          "value": "2026-01-12 to present",
          "created_at": "2026-01-13 04:57:01.229036"
        },
        {
          "id": 566,
          "dimension": "depth",
          "value": "used in data storage",
          "created_at": "2026-01-13 04:57:01.229036"
        },
        {
          "id": 567,
          "dimension": "autonomy",
          "value": "used with GitHub Actions",
          "created_at": "2026-01-13 04:57:01.229036"
        },
        {
          "id": 568,
          "dimension": "scale",
          "value": "data stored in cloud",
          "created_at": "2026-01-13 04:57:01.229036"
        },
        {
          "id": 569,
          "dimension": "constraint",
          "value": "no major challenges shown",
          "created_at": "2026-01-13 04:57:01.229562"
        },
        {
          "id": 570,
          "dimension": "production",
          "value": "used in production",
          "created_at": "2026-01-13 04:57:01.229562"
        }
      ],
      "evidence": [
        {
          "id": 213,
          "attribute": null,
          "content": "Datastores: PostgreSQL, Snowflake, S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:57:01.229562"
        },
        {
          "id": 214,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 04:57:01.229562"
        }
      ]
    },
    {
      "id": 96,
      "name": "aws",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples demonstrate practical experience with AWS services and related tools)",
      "created_at": "2026-01-13 04:57:01.230089",
      "dimensions": [
        {
          "id": 571,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.236533"
        },
        {
          "id": 572,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-13 04:57:01.237069"
        },
        {
          "id": 573,
          "dimension": "autonomy",
          "value": "collaborative work",
          "created_at": "2026-01-13 04:57:01.237069"
        },
        {
          "id": 574,
          "dimension": "scale",
          "value": "limited scope",
          "created_at": "2026-01-13 04:57:01.237069"
        },
        {
          "id": 575,
          "dimension": "constraint",
          "value": "resource limits",
          "created_at": "2026-01-13 04:57:01.237069"
        },
        {
          "id": 576,
          "dimension": "production",
          "value": "deployed in pipelines",
          "created_at": "2026-01-13 04:57:01.237069"
        }
      ],
      "evidence": [
        {
          "id": 215,
          "attribute": null,
          "content": "Datastores: PostgreSQL, Snowflake, S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:57:01.237069"
        },
        {
          "id": 216,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 04:57:01.237614"
        }
      ]
    },
    {
      "id": 97,
      "name": "docker",
      "meaningfulness_score": "High",
      "confidence": "High (extensive experience with Docker and related tools suggests strong proficiency)",
      "created_at": "2026-01-13 04:57:01.237614",
      "dimensions": [
        {
          "id": 577,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.245417"
        },
        {
          "id": 578,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-13 04:57:01.245417"
        },
        {
          "id": 579,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.245417"
        },
        {
          "id": 580,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.245417"
        },
        {
          "id": 581,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.245417"
        },
        {
          "id": 582,
          "dimension": "production",
          "value": "deployed system",
          "created_at": "2026-01-13 04:57:01.245959"
        }
      ],
      "evidence": [
        {
          "id": 217,
          "attribute": null,
          "content": "Infrastructure: Docker, Kubernetes, GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:57:01.245959"
        }
      ]
    },
    {
      "id": 98,
      "name": "kubernetes",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples demonstrate practical experience with Kubernetes in real-world scenarios)",
      "created_at": "2026-01-13 04:57:01.245959",
      "dimensions": [
        {
          "id": 583,
          "dimension": "duration",
          "value": "ongoing since early 2020",
          "created_at": "2026-01-13 04:57:01.252995"
        },
        {
          "id": 584,
          "dimension": "depth",
          "value": "practical understanding of Kubernetes",
          "created_at": "2026-01-13 04:57:01.252995"
        },
        {
          "id": 585,
          "dimension": "autonomy",
          "value": "executed tasks independently",
          "created_at": "2026-01-13 04:57:01.252995"
        },
        {
          "id": 586,
          "dimension": "scale",
          "value": "multiple jobs in Kubernetes",
          "created_at": "2026-01-13 04:57:01.253538"
        },
        {
          "id": 587,
          "dimension": "constraint",
          "value": "resource management challenges",
          "created_at": "2026-01-13 04:57:01.253538"
        },
        {
          "id": 588,
          "dimension": "production",
          "value": "used in live environment",
          "created_at": "2026-01-13 04:57:01.253538"
        }
      ],
      "evidence": [
        {
          "id": 218,
          "attribute": null,
          "content": "Infrastructure: Docker, Kubernetes, GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:57:01.253538"
        },
        {
          "id": 219,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 04:57:01.254079"
        }
      ]
    },
    {
      "id": 99,
      "name": "ci/cd",
      "meaningfulness_score": "High",
      "confidence": "High (demonstrates practical experience with core CI/CD tools and workflows)",
      "created_at": "2026-01-13 04:57:01.254079",
      "dimensions": [
        {
          "id": 589,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.262918"
        },
        {
          "id": 590,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-13 04:57:01.263505"
        },
        {
          "id": 591,
          "dimension": "autonomy",
          "value": "collaborative work",
          "created_at": "2026-01-13 04:57:01.263505"
        },
        {
          "id": 592,
          "dimension": "scale",
          "value": "deployment pipeline",
          "created_at": "2026-01-13 04:57:01.264041"
        },
        {
          "id": 593,
          "dimension": "constraint",
          "value": "deployment environment complexity",
          "created_at": "2026-01-13 04:57:01.264041"
        },
        {
          "id": 594,
          "dimension": "production",
          "value": "deployed with GitHub Actions",
          "created_at": "2026-01-13 04:57:01.264041"
        }
      ],
      "evidence": [
        {
          "id": 220,
          "attribute": null,
          "content": "Infrastructure: Docker, Kubernetes, GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:57:01.264041"
        },
        {
          "id": 221,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 04:57:01.264626"
        }
      ]
    },
    {
      "id": 100,
      "name": "Airflow",
      "meaningfulness_score": "High",
      "confidence": "Medium-High (evidence shows practical experience with Airflow in a relevant environment)",
      "created_at": "2026-01-13 04:57:01.264626",
      "dimensions": [
        {
          "id": 595,
          "dimension": "duration",
          "value": "recent",
          "created_at": "2026-01-13 04:57:01.271512"
        },
        {
          "id": 596,
          "dimension": "depth",
          "value": "intermediate",
          "created_at": "2026-01-13 04:57:01.272042"
        },
        {
          "id": 597,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.272042"
        },
        {
          "id": 598,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.272042"
        },
        {
          "id": 599,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 04:57:01.272042"
        },
        {
          "id": 600,
          "dimension": "production",
          "value": "deployed",
          "created_at": "2026-01-13 04:57:01.272042"
        }
      ],
      "evidence": [
        {
          "id": 222,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 04:57:01.272583"
        }
      ]
    },
    {
      "id": 101,
      "name": "python",
      "meaningfulness_score": "High",
      "confidence": "High (candidate demonstrates proficiency with Python, a core programming language in IT)",
      "created_at": "2026-01-13 05:09:53.515544",
      "dimensions": [
        {
          "id": 601,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.608366"
        },
        {
          "id": 602,
          "dimension": "depth",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.608366"
        },
        {
          "id": 603,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.608907"
        },
        {
          "id": 604,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.608907"
        },
        {
          "id": 605,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.608907"
        },
        {
          "id": 606,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.609448"
        }
      ],
      "evidence": [
        {
          "id": 232,
          "attribute": null,
          "content": "Languages: Python, SQL",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 05:09:53.609448"
        }
      ]
    },
    {
      "id": 102,
      "name": "SQL",
      "meaningfulness_score": "High",
      "confidence": "High (explicit mention of SQL alongside Python indicates confirmed proficiency)",
      "created_at": "2026-01-13 05:09:53.610531",
      "dimensions": [
        {
          "id": 607,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.643911"
        },
        {
          "id": 608,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-13 05:09:53.644917"
        },
        {
          "id": 609,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.644917"
        },
        {
          "id": 610,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.644917"
        },
        {
          "id": 611,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.645912"
        },
        {
          "id": 612,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.645912"
        }
      ],
      "evidence": [
        {
          "id": 233,
          "attribute": null,
          "content": "Languages: Python, SQL",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 05:09:53.645912"
        }
      ]
    },
    {
      "id": 103,
      "name": "Apache Airflow",
      "meaningfulness_score": "High",
      "confidence": "High (multiple mentions in relevant tools indicate strong familiarity)",
      "created_at": "2026-01-13 05:09:53.645912",
      "dimensions": [
        {
          "id": 613,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.654051"
        },
        {
          "id": 614,
          "dimension": "depth",
          "value": "framework expertise",
          "created_at": "2026-01-13 05:09:53.654051"
        },
        {
          "id": 615,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.655272"
        },
        {
          "id": 616,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.655272"
        },
        {
          "id": 617,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.655272"
        },
        {
          "id": 618,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.655272"
        }
      ],
      "evidence": [
        {
          "id": 234,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow, Spark, dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 05:09:53.655272"
        }
      ]
    },
    {
      "id": 104,
      "name": "spark",
      "meaningfulness_score": "High",
      "confidence": "High (multiple examples demonstrate practical application and understanding of Spark in relevant roles)",
      "created_at": "2026-01-13 05:09:53.655969",
      "dimensions": [
        {
          "id": 619,
          "dimension": "duration",
          "value": "2026-01-12 to present",
          "created_at": "2026-01-13 05:09:53.663696"
        },
        {
          "id": 620,
          "dimension": "depth",
          "value": "designed batch and streaming pipelines",
          "created_at": "2026-01-13 05:09:53.663696"
        },
        {
          "id": 621,
          "dimension": "autonomy",
          "value": "designed pipelines independently",
          "created_at": "2026-01-13 05:09:53.663696"
        },
        {
          "id": 622,
          "dimension": "scale",
          "value": "Kubernetes deployment environment",
          "created_at": "2026-01-13 05:09:53.664333"
        },
        {
          "id": 623,
          "dimension": "constraint",
          "value": "resource limits not specified",
          "created_at": "2026-01-13 05:09:53.664333"
        },
        {
          "id": 624,
          "dimension": "production",
          "value": "used in production",
          "created_at": "2026-01-13 05:09:53.664333"
        }
      ],
      "evidence": [
        {
          "id": 236,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 05:09:53.664333"
        },
        {
          "id": 235,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow, Spark, dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 05:09:53.664333"
        },
        {
          "id": 237,
          "attribute": null,
          "content": "I designed batch and streaming pipelines using Spark and Airflow, and built data models with dbt so analysts could trust the data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:19:40.564871",
          "created_at": "2026-01-13 05:09:53.664841"
        }
      ]
    },
    {
      "id": 105,
      "name": "dbt",
      "meaningfulness_score": "High",
      "confidence": "High (specific example demonstrates understanding beyond surface level)",
      "created_at": "2026-01-13 05:09:53.664841",
      "dimensions": [
        {
          "id": 625,
          "dimension": "duration",
          "value": "ongoing",
          "created_at": "2026-01-13 05:09:53.675221"
        },
        {
          "id": 626,
          "dimension": "depth",
          "value": "built data models",
          "created_at": "2026-01-13 05:09:53.675221"
        },
        {
          "id": 627,
          "dimension": "autonomy",
          "value": "designed pipelines independently",
          "created_at": "2026-01-13 05:09:53.675221"
        },
        {
          "id": 628,
          "dimension": "scale",
          "value": "data pipeline development",
          "created_at": "2026-01-13 05:09:53.675221"
        },
        {
          "id": 629,
          "dimension": "constraint",
          "value": "not specified",
          "created_at": "2026-01-13 05:09:53.675891"
        },
        {
          "id": 630,
          "dimension": "production",
          "value": "used in data analysis",
          "created_at": "2026-01-13 05:09:53.675891"
        }
      ],
      "evidence": [
        {
          "id": 239,
          "attribute": null,
          "content": "I designed batch and streaming pipelines using Spark and Airflow, and built data models with dbt so analysts could trust the data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:19:40.564871",
          "created_at": "2026-01-13 05:09:53.675891"
        },
        {
          "id": 238,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow, Spark, dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 05:09:53.675891"
        }
      ]
    },
    {
      "id": 106,
      "name": "postgresql",
      "meaningfulness_score": "High",
      "confidence": "High (candidate has demonstrated specific experience with PostgreSQL among other datastores, indicating practical familiarity)",
      "created_at": "2026-01-13 05:09:53.675891",
      "dimensions": [
        {
          "id": 631,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.683555"
        },
        {
          "id": 632,
          "dimension": "depth",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.683555"
        },
        {
          "id": 633,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.683555"
        },
        {
          "id": 634,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.683555"
        },
        {
          "id": 635,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.683555"
        },
        {
          "id": 636,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.684090"
        }
      ],
      "evidence": [
        {
          "id": 240,
          "attribute": null,
          "content": "Datastores: PostgreSQL, Snowflake, S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 05:09:53.684090"
        }
      ]
    },
    {
      "id": 107,
      "name": "Snowflake",
      "meaningfulness_score": "High",
      "confidence": "High (demonstrates practical experience with Snowflake in data storage and deployment pipelines)",
      "created_at": "2026-01-13 05:09:53.684090",
      "dimensions": [
        {
          "id": 637,
          "dimension": "duration",
          "value": "used as of 2026",
          "created_at": "2026-01-13 05:09:53.693042"
        },
        {
          "id": 638,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-13 05:09:53.693042"
        },
        {
          "id": 639,
          "dimension": "autonomy",
          "value": "used with GitHub Actions",
          "created_at": "2026-01-13 05:09:53.693042"
        },
        {
          "id": 640,
          "dimension": "scale",
          "value": "data stored in Snowflake",
          "created_at": "2026-01-13 05:09:53.693572"
        },
        {
          "id": 641,
          "dimension": "constraint",
          "value": "no specific challenges mentioned",
          "created_at": "2026-01-13 05:09:53.693572"
        },
        {
          "id": 642,
          "dimension": "production",
          "value": "used in data storage",
          "created_at": "2026-01-13 05:09:53.693572"
        }
      ],
      "evidence": [
        {
          "id": 241,
          "attribute": null,
          "content": "Datastores: PostgreSQL, Snowflake, S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 05:09:53.693572"
        },
        {
          "id": 242,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 05:09:53.694132"
        }
      ]
    },
    {
      "id": 108,
      "name": "aws",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples demonstrate practical experience with AWS services and deployment processes)",
      "created_at": "2026-01-13 05:09:53.694132",
      "dimensions": [
        {
          "id": 643,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.704169"
        },
        {
          "id": 644,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-13 05:09:53.704741"
        },
        {
          "id": 645,
          "dimension": "autonomy",
          "value": "collaborative work",
          "created_at": "2026-01-13 05:09:53.704741"
        },
        {
          "id": 646,
          "dimension": "scale",
          "value": "multiple datastores",
          "created_at": "2026-01-13 05:09:53.704741"
        },
        {
          "id": 647,
          "dimension": "constraint",
          "value": "deployment challenges",
          "created_at": "2026-01-13 05:09:53.704741"
        },
        {
          "id": 648,
          "dimension": "production",
          "value": "pipeline in production",
          "created_at": "2026-01-13 05:09:53.704741"
        }
      ],
      "evidence": [
        {
          "id": 244,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 05:09:53.704741"
        },
        {
          "id": 243,
          "attribute": null,
          "content": "Datastores: PostgreSQL, Snowflake, S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 05:09:53.704741"
        }
      ]
    },
    {
      "id": 109,
      "name": "docker",
      "meaningfulness_score": "High",
      "confidence": "High (multiple concrete examples demonstrate solid understanding)",
      "created_at": "2026-01-13 05:09:53.706869",
      "dimensions": [
        {
          "id": 649,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.716894"
        },
        {
          "id": 650,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-13 05:09:53.716894"
        },
        {
          "id": 651,
          "dimension": "autonomy",
          "value": "collaborative work",
          "created_at": "2026-01-13 05:09:53.716894"
        },
        {
          "id": 652,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.717403"
        },
        {
          "id": 653,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.717403"
        },
        {
          "id": 654,
          "dimension": "production",
          "value": "deployed in production",
          "created_at": "2026-01-13 05:09:53.717403"
        }
      ],
      "evidence": [
        {
          "id": 245,
          "attribute": null,
          "content": "Infrastructure: Docker, Kubernetes, GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 05:09:53.717403"
        }
      ]
    },
    {
      "id": 110,
      "name": "kubernetes",
      "meaningfulness_score": "High",
      "confidence": "High (specific example demonstrates practical application in real-world scenarios)",
      "created_at": "2026-01-13 05:09:53.717403",
      "dimensions": [
        {
          "id": 655,
          "dimension": "duration",
          "value": "Limited recent experience",
          "created_at": "2026-01-13 05:09:53.727342"
        },
        {
          "id": 656,
          "dimension": "depth",
          "value": "Intermediate knowledge",
          "created_at": "2026-01-13 05:09:53.727857"
        },
        {
          "id": 657,
          "dimension": "autonomy",
          "value": "Collaborative work",
          "created_at": "2026-01-13 05:09:53.727857"
        },
        {
          "id": 658,
          "dimension": "scale",
          "value": "Running Airflow and Spark",
          "created_at": "2026-01-13 05:09:53.727857"
        },
        {
          "id": 659,
          "dimension": "constraint",
          "value": "Resource management",
          "created_at": "2026-01-13 05:09:53.727857"
        },
        {
          "id": 660,
          "dimension": "production",
          "value": "Used in production",
          "created_at": "2026-01-13 05:09:53.727857"
        }
      ],
      "evidence": [
        {
          "id": 247,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 05:09:53.728434"
        },
        {
          "id": 246,
          "attribute": null,
          "content": "Infrastructure: Docker, Kubernetes, GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 05:09:53.728434"
        }
      ]
    },
    {
      "id": 111,
      "name": "ci/cd",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples demonstrate a comprehensive understanding of CI/CD pipelines and related tools)",
      "created_at": "2026-01-13 05:09:53.728434",
      "dimensions": [
        {
          "id": 661,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.735683"
        },
        {
          "id": 662,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-13 05:09:53.736220"
        },
        {
          "id": 663,
          "dimension": "autonomy",
          "value": "collaborative work",
          "created_at": "2026-01-13 05:09:53.736220"
        },
        {
          "id": 664,
          "dimension": "scale",
          "value": "enterprise level",
          "created_at": "2026-01-13 05:09:53.736220"
        },
        {
          "id": 665,
          "dimension": "constraint",
          "value": "deployment challenges",
          "created_at": "2026-01-13 05:09:53.736220"
        },
        {
          "id": 666,
          "dimension": "production",
          "value": "deployed in production",
          "created_at": "2026-01-13 05:09:53.736220"
        }
      ],
      "evidence": [
        {
          "id": 248,
          "attribute": null,
          "content": "Infrastructure: Docker, Kubernetes, GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 05:09:53.736220"
        },
        {
          "id": 249,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 05:09:53.736745"
        }
      ]
    },
    {
      "id": 112,
      "name": "Airflow",
      "meaningfulness_score": "High",
      "confidence": "Medium-High (experience with running Airflow in a Kubernetes environment suggests practical knowledge, but lacks detail on configuration or pipeline design)",
      "created_at": "2026-01-13 05:09:53.736745",
      "dimensions": [
        {
          "id": 667,
          "dimension": "duration",
          "value": "recent experience",
          "created_at": "2026-01-13 05:09:53.755863"
        },
        {
          "id": 668,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-13 05:09:53.755863"
        },
        {
          "id": 669,
          "dimension": "autonomy",
          "value": "operated independently",
          "created_at": "2026-01-13 05:09:53.756763"
        },
        {
          "id": 670,
          "dimension": "scale",
          "value": "Kubernetes environment",
          "created_at": "2026-01-13 05:09:53.756763"
        },
        {
          "id": 671,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-13 05:09:53.756763"
        },
        {
          "id": 672,
          "dimension": "production",
          "value": "deployed in production",
          "created_at": "2026-01-13 05:09:53.756763"
        }
      ],
      "evidence": [
        {
          "id": 250,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 05:09:53.757419"
        }
      ]
    },
    {
      "id": 113,
      "name": "python",
      "meaningfulness_score": "High",
      "confidence": "High (direct evidence of proficiency in Python)",
      "created_at": "2026-01-14 21:57:39.258459",
      "dimensions": [
        {
          "id": 673,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.314839"
        },
        {
          "id": 674,
          "dimension": "depth",
          "value": "basic scripting knowledge",
          "created_at": "2026-01-14 21:57:39.314839"
        },
        {
          "id": 675,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.314839"
        },
        {
          "id": 676,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.315364"
        },
        {
          "id": 677,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.315364"
        },
        {
          "id": 678,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.315364"
        }
      ],
      "evidence": [
        {
          "id": 259,
          "attribute": null,
          "content": "Languages: Python",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-14 21:57:39.315364"
        }
      ]
    },
    {
      "id": 114,
      "name": "SQL",
      "meaningfulness_score": "High",
      "confidence": "High (explicit mention of SQL language indicates genuine familiarity)",
      "created_at": "2026-01-14 21:57:39.315364",
      "dimensions": [
        {
          "id": 679,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.330497"
        },
        {
          "id": 680,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-14 21:57:39.330497"
        },
        {
          "id": 681,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.331038"
        },
        {
          "id": 682,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.331038"
        },
        {
          "id": 683,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.331038"
        },
        {
          "id": 684,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.331038"
        }
      ],
      "evidence": [
        {
          "id": 260,
          "attribute": null,
          "content": "Languages: SQL",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-14 21:57:39.331038"
        }
      ]
    },
    {
      "id": 115,
      "name": "Apache Airflow",
      "meaningfulness_score": "High",
      "confidence": "Medium-High (framework is widely used in data pipeline automation, but no specific experience details provided)",
      "created_at": "2026-01-14 21:57:39.331038",
      "dimensions": [
        {
          "id": 685,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.335440"
        },
        {
          "id": 686,
          "dimension": "depth",
          "value": "framework expertise",
          "created_at": "2026-01-14 21:57:39.335440"
        },
        {
          "id": 687,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.335440"
        },
        {
          "id": 688,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.335440"
        },
        {
          "id": 689,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.335440"
        },
        {
          "id": 690,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.335440"
        }
      ],
      "evidence": [
        {
          "id": 261,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-14 21:57:39.335440"
        }
      ]
    },
    {
      "id": 116,
      "name": "spark",
      "meaningfulness_score": "High",
      "confidence": "High (direct mention of running Spark jobs in a relevant environment demonstrates practical experience)",
      "created_at": "2026-01-14 21:57:39.335981",
      "dimensions": [
        {
          "id": 691,
          "dimension": "duration",
          "value": "used in recent projects",
          "created_at": "2026-01-14 21:57:39.339744"
        },
        {
          "id": 692,
          "dimension": "depth",
          "value": "framework knowledge",
          "created_at": "2026-01-14 21:57:39.339744"
        },
        {
          "id": 693,
          "dimension": "autonomy",
          "value": "operated in Kubernetes",
          "created_at": "2026-01-14 21:57:39.340265"
        },
        {
          "id": 694,
          "dimension": "scale",
          "value": "run Airflow and Spark jobs",
          "created_at": "2026-01-14 21:57:39.340265"
        },
        {
          "id": 695,
          "dimension": "constraint",
          "value": "resource limits in Kubernetes",
          "created_at": "2026-01-14 21:57:39.340265"
        },
        {
          "id": 696,
          "dimension": "production",
          "value": "deployed in live system",
          "created_at": "2026-01-14 21:57:39.340265"
        }
      ],
      "evidence": [
        {
          "id": 262,
          "attribute": null,
          "content": "Frameworks & Tools: Spark",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-14 21:57:39.340265"
        },
        {
          "id": 263,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:17:40",
          "created_at": "2026-01-14 21:57:39.340265"
        }
      ]
    },
    {
      "id": 117,
      "name": "dbt",
      "meaningfulness_score": "High",
      "confidence": "High (specific example demonstrates practical application in building data models with dbt)",
      "created_at": "2026-01-14 21:57:39.340265",
      "dimensions": [
        {
          "id": 697,
          "dimension": "duration",
          "value": "recently started",
          "created_at": "2026-01-14 21:57:39.346253"
        },
        {
          "id": 698,
          "dimension": "depth",
          "value": "built data models",
          "created_at": "2026-01-14 21:57:39.346253"
        },
        {
          "id": 699,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.346253"
        },
        {
          "id": 700,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.346253"
        },
        {
          "id": 701,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.346253"
        },
        {
          "id": 702,
          "dimension": "production",
          "value": "used in production",
          "created_at": "2026-01-14 21:57:39.346832"
        }
      ],
      "evidence": [
        {
          "id": 265,
          "attribute": null,
          "content": "built data models with dbt so analysts could trust the data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:19:40",
          "created_at": "2026-01-14 21:57:39.346832"
        },
        {
          "id": 264,
          "attribute": null,
          "content": "Frameworks & Tools: dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-14 21:57:39.346832"
        }
      ]
    },
    {
      "id": 118,
      "name": "postgresql",
      "meaningfulness_score": "High",
      "confidence": "High (specific mention of PostgreSQL as a datastore indicates direct experience with the skill)",
      "created_at": "2026-01-14 21:57:39.346832",
      "dimensions": [
        {
          "id": 703,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.351606"
        },
        {
          "id": 704,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-14 21:57:39.351606"
        },
        {
          "id": 705,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.352135"
        },
        {
          "id": 706,
          "dimension": "scale",
          "value": "single datastore",
          "created_at": "2026-01-14 21:57:39.352135"
        },
        {
          "id": 707,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.352135"
        },
        {
          "id": 708,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.352135"
        }
      ],
      "evidence": [
        {
          "id": 266,
          "attribute": null,
          "content": "Datastores: PostgreSQL",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-14 21:57:39.352135"
        }
      ]
    },
    {
      "id": 119,
      "name": "Snowflake",
      "meaningfulness_score": "High",
      "confidence": "High (evidence directly references Snowflake as a datastore, demonstrating familiarity and practical experience)",
      "created_at": "2026-01-14 21:57:39.352135",
      "dimensions": [
        {
          "id": 709,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.356315"
        },
        {
          "id": 710,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-14 21:57:39.356315"
        },
        {
          "id": 711,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.356315"
        },
        {
          "id": 712,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.356315"
        },
        {
          "id": 713,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.356315"
        },
        {
          "id": 714,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.356315"
        }
      ],
      "evidence": [
        {
          "id": 267,
          "attribute": null,
          "content": "Datastores: Snowflake",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-14 21:57:39.356315"
        },
        {
          "id": 268,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3,",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:17:40",
          "created_at": "2026-01-14 21:57:39.356850"
        }
      ]
    },
    {
      "id": 120,
      "name": "aws",
      "meaningfulness_score": "High",
      "confidence": "High (multiple relevant AWS services demonstrated, indicating practical familiarity)",
      "created_at": "2026-01-14 21:57:39.356850",
      "dimensions": [
        {
          "id": 715,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.360885"
        },
        {
          "id": 716,
          "dimension": "depth",
          "value": "basic data storage",
          "created_at": "2026-01-14 21:57:39.360885"
        },
        {
          "id": 717,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.360885"
        },
        {
          "id": 718,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.360885"
        },
        {
          "id": 719,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.361400"
        },
        {
          "id": 720,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.361400"
        }
      ],
      "evidence": [
        {
          "id": 270,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3,",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:17:40",
          "created_at": "2026-01-14 21:57:39.361400"
        },
        {
          "id": 269,
          "attribute": null,
          "content": "Datastores: S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-14 21:57:39.361400"
        }
      ]
    },
    {
      "id": 121,
      "name": "docker",
      "meaningfulness_score": "High",
      "confidence": "High (explicit mention of Docker in infrastructure indicates practical familiarity)",
      "created_at": "2026-01-14 21:57:39.361400",
      "dimensions": [
        {
          "id": 721,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.365626"
        },
        {
          "id": 722,
          "dimension": "depth",
          "value": "basic containerization",
          "created_at": "2026-01-14 21:57:39.366140"
        },
        {
          "id": 723,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.366140"
        },
        {
          "id": 724,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.366140"
        },
        {
          "id": 725,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.366140"
        },
        {
          "id": 726,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.366140"
        }
      ],
      "evidence": [
        {
          "id": 271,
          "attribute": null,
          "content": "Infrastructure: Docker",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-14 21:57:39.366140"
        }
      ]
    },
    {
      "id": 122,
      "name": "kubernetes",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples of running complex workloads demonstrate practical proficiency)",
      "created_at": "2026-01-14 21:57:39.366687",
      "dimensions": [
        {
          "id": 727,
          "dimension": "duration",
          "value": "long-term experience",
          "created_at": "2026-01-14 21:57:39.370494"
        },
        {
          "id": 728,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-14 21:57:39.370494"
        },
        {
          "id": 729,
          "dimension": "autonomy",
          "value": "independent work",
          "created_at": "2026-01-14 21:57:39.371039"
        },
        {
          "id": 730,
          "dimension": "scale",
          "value": "run jobs in Kubernetes",
          "created_at": "2026-01-14 21:57:39.371039"
        },
        {
          "id": 731,
          "dimension": "constraint",
          "value": "resource management issues",
          "created_at": "2026-01-14 21:57:39.371039"
        },
        {
          "id": 732,
          "dimension": "production",
          "value": "used in production",
          "created_at": "2026-01-14 21:57:39.371039"
        }
      ],
      "evidence": [
        {
          "id": 272,
          "attribute": null,
          "content": "Infrastructure: Kubernetes",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-14 21:57:39.371039"
        },
        {
          "id": 273,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:17:40",
          "created_at": "2026-01-14 21:57:39.371039"
        }
      ]
    },
    {
      "id": 123,
      "name": "ci/cd",
      "meaningfulness_score": "High",
      "confidence": "High (specific example demonstrates practical use and understanding in real-world scenarios)",
      "created_at": "2026-01-14 21:57:39.371039",
      "dimensions": [
        {
          "id": 733,
          "dimension": "duration",
          "value": "used since 2026",
          "created_at": "2026-01-14 21:57:39.375264"
        },
        {
          "id": 734,
          "dimension": "depth",
          "value": "basic understanding of CI/CD",
          "created_at": "2026-01-14 21:57:39.375808"
        },
        {
          "id": 735,
          "dimension": "autonomy",
          "value": "implemented independently",
          "created_at": "2026-01-14 21:57:39.375808"
        },
        {
          "id": 736,
          "dimension": "scale",
          "value": "single project",
          "created_at": "2026-01-14 21:57:39.375808"
        },
        {
          "id": 737,
          "dimension": "constraint",
          "value": "no specific challenges",
          "created_at": "2026-01-14 21:57:39.375808"
        },
        {
          "id": 738,
          "dimension": "production",
          "value": "deployed in production",
          "created_at": "2026-01-14 21:57:39.375808"
        }
      ],
      "evidence": [
        {
          "id": 275,
          "attribute": null,
          "content": "we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:17:40",
          "created_at": "2026-01-14 21:57:39.375808"
        },
        {
          "id": 274,
          "attribute": null,
          "content": "Infrastructure: GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-14 21:57:39.375808"
        }
      ]
    },
    {
      "id": 124,
      "name": "Airflow",
      "meaningfulness_score": "High",
      "confidence": "Medium-High (evidence shows practical experience with Airflow in a relevant environment)",
      "created_at": "2026-01-14 21:57:39.375808",
      "dimensions": [
        {
          "id": 739,
          "dimension": "duration",
          "value": "recent deployment",
          "created_at": "2026-01-14 21:57:39.379919"
        },
        {
          "id": 740,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-14 21:57:39.380440"
        },
        {
          "id": 741,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.380440"
        },
        {
          "id": 742,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.380440"
        },
        {
          "id": 743,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.380440"
        },
        {
          "id": 744,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-14 21:57:39.380440"
        }
      ],
      "evidence": [
        {
          "id": 276,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:17:40",
          "created_at": "2026-01-14 21:57:39.380440"
        }
      ]
    },
    {
      "id": 125,
      "name": "python",
      "meaningfulness_score": "High",
      "confidence": "High (direct mention of Python as a language skill indicates strong proficiency)",
      "created_at": "2026-01-19 06:10:44.145346",
      "dimensions": [
        {
          "id": 745,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.345181"
        },
        {
          "id": 746,
          "dimension": "depth",
          "value": "basic scripting",
          "created_at": "2026-01-19 06:10:44.345181"
        },
        {
          "id": 747,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.345181"
        },
        {
          "id": 748,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.345181"
        },
        {
          "id": 749,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.345181"
        },
        {
          "id": 750,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.345181"
        }
      ],
      "evidence": [
        {
          "id": 286,
          "attribute": null,
          "content": "Languages: Python",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 06:10:44.345181"
        }
      ]
    },
    {
      "id": 126,
      "name": "SQL",
      "meaningfulness_score": "High",
      "confidence": "High (direct mention of SQL language indicates solid familiarity)",
      "created_at": "2026-01-19 06:10:44.346191",
      "dimensions": [
        {
          "id": 751,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.363644"
        },
        {
          "id": 752,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-19 06:10:44.364174"
        },
        {
          "id": 753,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.364174"
        },
        {
          "id": 754,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.364174"
        },
        {
          "id": 755,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.364174"
        },
        {
          "id": 756,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.364702"
        }
      ],
      "evidence": [
        {
          "id": 287,
          "attribute": null,
          "content": "Languages: SQL",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 06:10:44.364702"
        }
      ]
    },
    {
      "id": 127,
      "name": "Apache Airflow",
      "meaningfulness_score": "High",
      "confidence": "High (candidate explicitly lists Apache Airflow as a framework/tool they are familiar with)",
      "created_at": "2026-01-19 06:10:44.365229",
      "dimensions": [
        {
          "id": 757,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.373086"
        },
        {
          "id": 758,
          "dimension": "depth",
          "value": "basic familiarity",
          "created_at": "2026-01-19 06:10:44.373620"
        },
        {
          "id": 759,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.373620"
        },
        {
          "id": 760,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.373620"
        },
        {
          "id": 761,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.373620"
        },
        {
          "id": 762,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.373620"
        }
      ],
      "evidence": [
        {
          "id": 288,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 06:10:44.374147"
        }
      ]
    },
    {
      "id": 128,
      "name": "spark",
      "meaningfulness_score": "High",
      "confidence": "High (specific example demonstrates understanding beyond surface level)",
      "created_at": "2026-01-19 06:10:44.374147",
      "dimensions": [
        {
          "id": 763,
          "dimension": "duration",
          "value": "used in recent projects",
          "created_at": "2026-01-19 06:10:44.380655"
        },
        {
          "id": 764,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-19 06:10:44.380655"
        },
        {
          "id": 765,
          "dimension": "autonomy",
          "value": "collaborative work",
          "created_at": "2026-01-19 06:10:44.380655"
        },
        {
          "id": 766,
          "dimension": "scale",
          "value": "pipeline development",
          "created_at": "2026-01-19 06:10:44.381160"
        },
        {
          "id": 767,
          "dimension": "constraint",
          "value": "performance optimization",
          "created_at": "2026-01-19 06:10:44.381160"
        },
        {
          "id": 768,
          "dimension": "production",
          "value": "deployed pipelines",
          "created_at": "2026-01-19 06:10:44.381160"
        }
      ],
      "evidence": [
        {
          "id": 289,
          "attribute": null,
          "content": "Frameworks & Tools: Spark",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 06:10:44.381160"
        },
        {
          "id": 290,
          "attribute": null,
          "content": "We designed batch and streaming pipelines using Spark and Airflow.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:19:40.564871",
          "created_at": "2026-01-19 06:10:44.381160"
        }
      ]
    },
    {
      "id": 129,
      "name": "dbt",
      "meaningfulness_score": "High",
      "confidence": "High (specific example demonstrates practical experience in building data models with dbt)",
      "created_at": "2026-01-19 06:10:44.381160",
      "dimensions": [
        {
          "id": 769,
          "dimension": "duration",
          "value": "built data models recently",
          "created_at": "2026-01-19 06:10:44.391111"
        },
        {
          "id": 770,
          "dimension": "depth",
          "value": "data modeling expertise",
          "created_at": "2026-01-19 06:10:44.391111"
        },
        {
          "id": 771,
          "dimension": "autonomy",
          "value": "independent model building",
          "created_at": "2026-01-19 06:10:44.391111"
        },
        {
          "id": 772,
          "dimension": "scale",
          "value": "not specified",
          "created_at": "2026-01-19 06:10:44.391641"
        },
        {
          "id": 773,
          "dimension": "constraint",
          "value": "not specified",
          "created_at": "2026-01-19 06:10:44.391641"
        },
        {
          "id": 774,
          "dimension": "production",
          "value": "trusted data models",
          "created_at": "2026-01-19 06:10:44.391641"
        }
      ],
      "evidence": [
        {
          "id": 291,
          "attribute": null,
          "content": "Frameworks & Tools: dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 06:10:44.391641"
        },
        {
          "id": 292,
          "attribute": null,
          "content": "built data models with dbt so analysts could trust the data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:19:40.564871",
          "created_at": "2026-01-19 06:10:44.391641"
        }
      ]
    },
    {
      "id": 130,
      "name": "postgresql",
      "meaningfulness_score": "High",
      "confidence": "High (clear evidence of PostgreSQL experience in datastore management)",
      "created_at": "2026-01-19 06:10:44.392158",
      "dimensions": [
        {
          "id": 775,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.400925"
        },
        {
          "id": 776,
          "dimension": "depth",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.401457"
        },
        {
          "id": 777,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.401457"
        },
        {
          "id": 778,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.401457"
        },
        {
          "id": 779,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.401457"
        },
        {
          "id": 780,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.401457"
        }
      ],
      "evidence": [
        {
          "id": 293,
          "attribute": null,
          "content": "Datastores: PostgreSQL",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 06:10:44.401457"
        }
      ]
    },
    {
      "id": 131,
      "name": "Snowflake",
      "meaningfulness_score": "High",
      "confidence": "Medium-High (evidence indicates hands-on experience with Snowflake as a data store, but lacks detail on depth of expertise)",
      "created_at": "2026-01-19 06:10:44.401457",
      "dimensions": [
        {
          "id": 781,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.408085"
        },
        {
          "id": 782,
          "dimension": "depth",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.408085"
        },
        {
          "id": 783,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.408085"
        },
        {
          "id": 784,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.408604"
        },
        {
          "id": 785,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.408604"
        },
        {
          "id": 786,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.408604"
        }
      ],
      "evidence": [
        {
          "id": 294,
          "attribute": null,
          "content": "Datastores: Snowflake",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 06:10:44.408604"
        },
        {
          "id": 295,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-19 06:10:44.408604"
        }
      ]
    },
    {
      "id": 132,
      "name": "aws",
      "meaningfulness_score": "High",
      "confidence": "Medium-High (evidence shows familiarity with AWS storage services, but lacks detail on broader AWS skills)",
      "created_at": "2026-01-19 06:10:44.408604",
      "dimensions": [
        {
          "id": 787,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.414111"
        },
        {
          "id": 788,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-19 06:10:44.414652"
        },
        {
          "id": 789,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.414652"
        },
        {
          "id": 790,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.414652"
        },
        {
          "id": 791,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.414652"
        },
        {
          "id": 792,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.414652"
        }
      ],
      "evidence": [
        {
          "id": 296,
          "attribute": null,
          "content": "Datastores: S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 06:10:44.414652"
        },
        {
          "id": 297,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-19 06:10:44.415187"
        }
      ]
    },
    {
      "id": 133,
      "name": "docker",
      "meaningfulness_score": "High",
      "confidence": "High (explicit mention of Docker infrastructure indicates strong familiarity)",
      "created_at": "2026-01-19 06:10:44.415187",
      "dimensions": [
        {
          "id": 793,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.422773"
        },
        {
          "id": 794,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-19 06:10:44.422773"
        },
        {
          "id": 795,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.422773"
        },
        {
          "id": 796,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.423312"
        },
        {
          "id": 797,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.423312"
        },
        {
          "id": 798,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.423312"
        }
      ],
      "evidence": [
        {
          "id": 298,
          "attribute": null,
          "content": "Infrastructure: Docker",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 06:10:44.423312"
        }
      ]
    },
    {
      "id": 134,
      "name": "kubernetes",
      "meaningfulness_score": "High",
      "confidence": "High (evidence demonstrates practical experience managing Kubernetes infrastructure and running complex workloads)",
      "created_at": "2026-01-19 06:10:44.423312",
      "dimensions": [
        {
          "id": 799,
          "dimension": "duration",
          "value": "ongoing since 2026",
          "created_at": "2026-01-19 06:10:44.429295"
        },
        {
          "id": 800,
          "dimension": "depth",
          "value": "practical application",
          "created_at": "2026-01-19 06:10:44.429295"
        },
        {
          "id": 801,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.429295"
        },
        {
          "id": 802,
          "dimension": "scale",
          "value": "run Airflow and Spark jobs",
          "created_at": "2026-01-19 06:10:44.429295"
        },
        {
          "id": 803,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.429859"
        },
        {
          "id": 804,
          "dimension": "production",
          "value": "used in production",
          "created_at": "2026-01-19 06:10:44.429859"
        }
      ],
      "evidence": [
        {
          "id": 299,
          "attribute": null,
          "content": "Infrastructure: Kubernetes",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 06:10:44.429859"
        },
        {
          "id": 300,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-19 06:10:44.429859"
        }
      ]
    },
    {
      "id": 135,
      "name": "ci/cd",
      "meaningfulness_score": "High",
      "confidence": "High (specific example demonstrates practical implementation of CI/CD pipelines using GitHub Actions)",
      "created_at": "2026-01-19 06:10:44.429859",
      "dimensions": [
        {
          "id": 805,
          "dimension": "duration",
          "value": "ongoing use since 2026",
          "created_at": "2026-01-19 06:10:44.436447"
        },
        {
          "id": 806,
          "dimension": "depth",
          "value": "basic familiarity",
          "created_at": "2026-01-19 06:10:44.436447"
        },
        {
          "id": 807,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.436447"
        },
        {
          "id": 808,
          "dimension": "scale",
          "value": "single project scope",
          "created_at": "2026-01-19 06:10:44.436979"
        },
        {
          "id": 809,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.436979"
        },
        {
          "id": 810,
          "dimension": "production",
          "value": "deployed pipeline changes",
          "created_at": "2026-01-19 06:10:44.436979"
        }
      ],
      "evidence": [
        {
          "id": 301,
          "attribute": null,
          "content": "Infrastructure: GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 06:10:44.436979"
        },
        {
          "id": 302,
          "attribute": null,
          "content": "we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-19 06:10:44.436979"
        }
      ]
    },
    {
      "id": 136,
      "name": "Airflow",
      "meaningfulness_score": "High",
      "confidence": "High (multiple instances of pipeline design and execution demonstrate strong practical experience)",
      "created_at": "2026-01-19 06:10:44.436979",
      "dimensions": [
        {
          "id": 811,
          "dimension": "duration",
          "value": "multiple years",
          "created_at": "2026-01-19 06:10:44.443034"
        },
        {
          "id": 812,
          "dimension": "depth",
          "value": "designed pipelines",
          "created_at": "2026-01-19 06:10:44.443034"
        },
        {
          "id": 813,
          "dimension": "autonomy",
          "value": "designed and ran jobs",
          "created_at": "2026-01-19 06:10:44.443642"
        },
        {
          "id": 814,
          "dimension": "scale",
          "value": "batch and streaming pipelines",
          "created_at": "2026-01-19 06:10:44.443642"
        },
        {
          "id": 815,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.443642"
        },
        {
          "id": 816,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-19 06:10:44.443642"
        }
      ],
      "evidence": [
        {
          "id": 303,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-19 06:10:44.443642"
        },
        {
          "id": 304,
          "attribute": null,
          "content": "I designed batch and streaming pipelines using Spark and Airflow.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:19:40.564871",
          "created_at": "2026-01-19 06:10:44.444170"
        },
        {
          "id": 305,
          "attribute": null,
          "content": "We designed batch and streaming pipelines using Spark and Airflow.",
          "source_type": "conversation",
          "source_reference": "2026-01-13T08:11:09.18286",
          "created_at": "2026-01-19 06:10:44.444170"
        }
      ]
    },
    {
      "id": 137,
      "name": "python",
      "meaningfulness_score": "High",
      "confidence": "High (Python is fundamental in many IT roles, and evidence of proficiency is clear)",
      "created_at": "2026-01-19 07:42:44.716662",
      "dimensions": [
        {
          "id": 817,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.761478"
        },
        {
          "id": 818,
          "dimension": "depth",
          "value": "basic programming knowledge",
          "created_at": "2026-01-19 07:42:44.761478"
        },
        {
          "id": 819,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.761478"
        },
        {
          "id": 820,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.761478"
        },
        {
          "id": 821,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.761478"
        },
        {
          "id": 822,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.761478"
        }
      ],
      "evidence": [
        {
          "id": 315,
          "attribute": null,
          "content": "Languages: Python, SQL",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 07:42:44.761478"
        }
      ]
    },
    {
      "id": 138,
      "name": "SQL",
      "meaningfulness_score": "High",
      "confidence": "High (direct mention of SQL indicates solid familiarity with core database querying skills)",
      "created_at": "2026-01-19 07:42:44.761478",
      "dimensions": [
        {
          "id": 823,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.773549"
        },
        {
          "id": 824,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-19 07:42:44.773549"
        },
        {
          "id": 825,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.773549"
        },
        {
          "id": 826,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.773549"
        },
        {
          "id": 827,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.773549"
        },
        {
          "id": 828,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.773549"
        }
      ],
      "evidence": [
        {
          "id": 316,
          "attribute": null,
          "content": "Languages: Python, SQL",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 07:42:44.773549"
        }
      ]
    },
    {
      "id": 139,
      "name": "Apache Airflow",
      "meaningfulness_score": "High",
      "confidence": "High (multiple mentions in relevant tools and frameworks demonstrate solid familiarity)",
      "created_at": "2026-01-19 07:42:44.774069",
      "dimensions": [
        {
          "id": 829,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.777855"
        },
        {
          "id": 830,
          "dimension": "depth",
          "value": "integrated tool knowledge",
          "created_at": "2026-01-19 07:42:44.777855"
        },
        {
          "id": 831,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.777855"
        },
        {
          "id": 832,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.777855"
        },
        {
          "id": 833,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.777855"
        },
        {
          "id": 834,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.777855"
        }
      ],
      "evidence": [
        {
          "id": 317,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow, Spark, dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 07:42:44.777855"
        }
      ]
    },
    {
      "id": 140,
      "name": "spark",
      "meaningfulness_score": "High",
      "confidence": "High (specific example demonstrates understanding beyond surface level)",
      "created_at": "2026-01-19 07:42:44.777855",
      "dimensions": [
        {
          "id": 835,
          "dimension": "duration",
          "value": "used in 2026",
          "created_at": "2026-01-19 07:42:44.782326"
        },
        {
          "id": 836,
          "dimension": "depth",
          "value": "designed pipelines",
          "created_at": "2026-01-19 07:42:44.782326"
        },
        {
          "id": 837,
          "dimension": "autonomy",
          "value": "designed pipelines",
          "created_at": "2026-01-19 07:42:44.782326"
        },
        {
          "id": 838,
          "dimension": "scale",
          "value": "batch and streaming",
          "created_at": "2026-01-19 07:42:44.782326"
        },
        {
          "id": 839,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.782326"
        },
        {
          "id": 840,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.782326"
        }
      ],
      "evidence": [
        {
          "id": 318,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow, Spark, dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 07:42:44.782326"
        },
        {
          "id": 319,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:17:40",
          "created_at": "2026-01-19 07:42:44.782860"
        },
        {
          "id": 320,
          "attribute": null,
          "content": "I designed batch and streaming pipelines using Spark and Airflow",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:19:40",
          "created_at": "2026-01-19 07:42:44.782860"
        }
      ]
    },
    {
      "id": 141,
      "name": "dbt",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples indicate direct experience with dbt and understanding of its application in data modeling)",
      "created_at": "2026-01-19 07:42:44.782860",
      "dimensions": [
        {
          "id": 841,
          "dimension": "duration",
          "value": "ongoing since 2026",
          "created_at": "2026-01-19 07:42:44.789454"
        },
        {
          "id": 842,
          "dimension": "depth",
          "value": "built data models with dbt",
          "created_at": "2026-01-19 07:42:44.789454"
        },
        {
          "id": 843,
          "dimension": "autonomy",
          "value": "designed pipelines independently",
          "created_at": "2026-01-19 07:42:44.789454"
        },
        {
          "id": 844,
          "dimension": "scale",
          "value": "not specified",
          "created_at": "2026-01-19 07:42:44.789454"
        },
        {
          "id": 845,
          "dimension": "constraint",
          "value": "not specified",
          "created_at": "2026-01-19 07:42:44.789454"
        },
        {
          "id": 846,
          "dimension": "production",
          "value": "data trusted by analysts",
          "created_at": "2026-01-19 07:42:44.789454"
        }
      ],
      "evidence": [
        {
          "id": 321,
          "attribute": null,
          "content": "Frameworks & Tools: Apache Airflow, Spark, dbt",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 07:42:44.789454"
        },
        {
          "id": 322,
          "attribute": null,
          "content": "built data models with dbt so analysts could trust the data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:19:40",
          "created_at": "2026-01-19 07:42:44.789454"
        },
        {
          "id": 323,
          "attribute": null,
          "content": "I designed batch and streaming pipelines using Spark and Airflow, and built data models with dbt so analysts could trust the data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:19:40",
          "created_at": "2026-01-19 07:42:44.789992"
        }
      ]
    },
    {
      "id": 142,
      "name": "postgresql",
      "meaningfulness_score": "High",
      "confidence": "High (candidate has demonstrated specific experience with PostgreSQL in a relevant context)",
      "created_at": "2026-01-19 07:42:44.789992",
      "dimensions": [
        {
          "id": 847,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.793554"
        },
        {
          "id": 848,
          "dimension": "depth",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.793554"
        },
        {
          "id": 849,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.793554"
        },
        {
          "id": 850,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.793554"
        },
        {
          "id": 851,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.793554"
        },
        {
          "id": 852,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.793554"
        }
      ],
      "evidence": [
        {
          "id": 324,
          "attribute": null,
          "content": "Datastores: PostgreSQL, Snowflake, S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 07:42:44.793554"
        }
      ]
    },
    {
      "id": 143,
      "name": "Snowflake",
      "meaningfulness_score": "High",
      "confidence": "Medium-High (evidence shows practical use of Snowflake in data storage, but lacks detailed context)",
      "created_at": "2026-01-19 07:42:44.793554",
      "dimensions": [
        {
          "id": 853,
          "dimension": "duration",
          "value": "ongoing or recent",
          "created_at": "2026-01-19 07:42:44.798261"
        },
        {
          "id": 854,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-19 07:42:44.798261"
        },
        {
          "id": 855,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.798261"
        },
        {
          "id": 856,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.798261"
        },
        {
          "id": 857,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.798261"
        },
        {
          "id": 858,
          "dimension": "production",
          "value": "used in production",
          "created_at": "2026-01-19 07:42:44.798261"
        }
      ],
      "evidence": [
        {
          "id": 325,
          "attribute": null,
          "content": "Datastores: PostgreSQL, Snowflake, S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 07:42:44.798261"
        },
        {
          "id": 326,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:17:40",
          "created_at": "2026-01-19 07:42:44.798786"
        }
      ]
    },
    {
      "id": 144,
      "name": "aws",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples demonstrate practical knowledge of AWS services and data management)",
      "created_at": "2026-01-19 07:42:44.798786",
      "dimensions": [
        {
          "id": 859,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.804123"
        },
        {
          "id": 860,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-19 07:42:44.804647"
        },
        {
          "id": 861,
          "dimension": "autonomy",
          "value": "collaborative work",
          "created_at": "2026-01-19 07:42:44.804647"
        },
        {
          "id": 862,
          "dimension": "scale",
          "value": "small data storage",
          "created_at": "2026-01-19 07:42:44.804647"
        },
        {
          "id": 863,
          "dimension": "constraint",
          "value": "no specific challenges",
          "created_at": "2026-01-19 07:42:44.804647"
        },
        {
          "id": 864,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.804647"
        }
      ],
      "evidence": [
        {
          "id": 327,
          "attribute": null,
          "content": "Datastores: PostgreSQL, Snowflake, S3",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 07:42:44.805170"
        },
        {
          "id": 328,
          "attribute": null,
          "content": "Data was stored in Snowflake and S3",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:17:40",
          "created_at": "2026-01-19 07:42:44.805170"
        }
      ]
    },
    {
      "id": 145,
      "name": "docker",
      "meaningfulness_score": "High",
      "confidence": "High (multiple relevant tools listed, indicating solid understanding of containerization and orchestration)",
      "created_at": "2026-01-19 07:42:44.805170",
      "dimensions": [
        {
          "id": 865,
          "dimension": "duration",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.810685"
        },
        {
          "id": 866,
          "dimension": "depth",
          "value": "intermediate knowledge",
          "created_at": "2026-01-19 07:42:44.810685"
        },
        {
          "id": 867,
          "dimension": "autonomy",
          "value": "collaborative work",
          "created_at": "2026-01-19 07:42:44.810685"
        },
        {
          "id": 868,
          "dimension": "scale",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.810685"
        },
        {
          "id": 869,
          "dimension": "constraint",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.810685"
        },
        {
          "id": 870,
          "dimension": "production",
          "value": "deployed in production",
          "created_at": "2026-01-19 07:42:44.810685"
        }
      ],
      "evidence": [
        {
          "id": 329,
          "attribute": null,
          "content": "Infrastructure: Docker, Kubernetes, GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 07:42:44.811255"
        }
      ]
    },
    {
      "id": 146,
      "name": "kubernetes",
      "meaningfulness_score": "High",
      "confidence": "High (specific example of running Airflow and Spark jobs demonstrates practical knowledge of Kubernetes in real-world scenarios)",
      "created_at": "2026-01-19 07:42:44.811255",
      "dimensions": [
        {
          "id": 871,
          "dimension": "duration",
          "value": "ongoing since 2026",
          "created_at": "2026-01-19 07:42:44.816092"
        },
        {
          "id": 872,
          "dimension": "depth",
          "value": "practical experience with Airflow and Spark",
          "created_at": "2026-01-19 07:42:44.816706"
        },
        {
          "id": 873,
          "dimension": "autonomy",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.816706"
        },
        {
          "id": 874,
          "dimension": "scale",
          "value": "Kubernetes environment",
          "created_at": "2026-01-19 07:42:44.816706"
        },
        {
          "id": 875,
          "dimension": "constraint",
          "value": "resource limits",
          "created_at": "2026-01-19 07:42:44.816706"
        },
        {
          "id": 876,
          "dimension": "production",
          "value": "deployed in production",
          "created_at": "2026-01-19 07:42:44.816706"
        }
      ],
      "evidence": [
        {
          "id": 330,
          "attribute": null,
          "content": "Infrastructure: Docker, Kubernetes, GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 07:42:44.816706"
        },
        {
          "id": 331,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:17:40",
          "created_at": "2026-01-19 07:42:44.816706"
        }
      ]
    },
    {
      "id": 147,
      "name": "ci/cd",
      "meaningfulness_score": "High",
      "confidence": "High (specific example demonstrates understanding beyond surface level)",
      "created_at": "2026-01-19 07:42:44.816706",
      "dimensions": [
        {
          "id": 877,
          "dimension": "duration",
          "value": "recently started",
          "created_at": "2026-01-19 07:42:44.822571"
        },
        {
          "id": 878,
          "dimension": "depth",
          "value": "basic knowledge",
          "created_at": "2026-01-19 07:42:44.822571"
        },
        {
          "id": 879,
          "dimension": "autonomy",
          "value": "collaborative work",
          "created_at": "2026-01-19 07:42:44.822571"
        },
        {
          "id": 880,
          "dimension": "scale",
          "value": "small deployment scope",
          "created_at": "2026-01-19 07:42:44.822571"
        },
        {
          "id": 881,
          "dimension": "constraint",
          "value": "limited info on challenges",
          "created_at": "2026-01-19 07:42:44.822571"
        },
        {
          "id": 882,
          "dimension": "production",
          "value": "deployed using GitHub Actions",
          "created_at": "2026-01-19 07:42:44.822571"
        }
      ],
      "evidence": [
        {
          "id": 332,
          "attribute": null,
          "content": "Infrastructure: Docker, Kubernetes, GitHub Actions",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 07:42:44.822571"
        },
        {
          "id": 333,
          "attribute": null,
          "content": "we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:17:40",
          "created_at": "2026-01-19 07:42:44.822571"
        }
      ]
    },
    {
      "id": 148,
      "name": "Airflow",
      "meaningfulness_score": "High",
      "confidence": "High (specific examples demonstrate practical experience and understanding of Airflow in real-world scenarios)",
      "created_at": "2026-01-19 07:42:44.822571",
      "dimensions": [
        {
          "id": 883,
          "dimension": "duration",
          "value": "recent experience",
          "created_at": "2026-01-19 07:42:44.828302"
        },
        {
          "id": 884,
          "dimension": "depth",
          "value": "designed pipelines",
          "created_at": "2026-01-19 07:42:44.828302"
        },
        {
          "id": 885,
          "dimension": "autonomy",
          "value": "independent work",
          "created_at": "2026-01-19 07:42:44.828302"
        },
        {
          "id": 886,
          "dimension": "scale",
          "value": "not specified",
          "created_at": "2026-01-19 07:42:44.828302"
        },
        {
          "id": 887,
          "dimension": "constraint",
          "value": "not specified",
          "created_at": "2026-01-19 07:42:44.828302"
        },
        {
          "id": 888,
          "dimension": "production",
          "value": "N/A",
          "created_at": "2026-01-19 07:42:44.828302"
        }
      ],
      "evidence": [
        {
          "id": 334,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:17:40",
          "created_at": "2026-01-19 07:42:44.828302"
        },
        {
          "id": 335,
          "attribute": null,
          "content": "I designed batch and streaming pipelines using Spark and Airflow",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:19:40",
          "created_at": "2026-01-19 07:42:44.828302"
        }
      ]
    }
  ],
  "behavioral_observations": [
    {
      "id": 31,
      "category": "Technical Leadership",
      "observation": "Technical Leadership (High (specific example demonstrates leadership in a complex technical project))",
      "confidence": "High (specific example demonstrates leadership in a complex technical project)",
      "created_at": "2026-01-12 05:09:43.827134",
      "evidence": [
        {
          "id": 125,
          "attribute": null,
          "content": "Led a migration from on-premise data warehouse to Snowflake, improving query performance and reducing infrastructure costs.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-12 05:09:43.837706"
        }
      ]
    },
    {
      "id": 32,
      "category": "Autonomy",
      "observation": "Autonomy (Medium-High (demonstrates ability to work independently on complex data projects))",
      "confidence": "Medium-High (demonstrates ability to work independently on complex data projects)",
      "created_at": "2026-01-12 05:09:43.837706",
      "evidence": [
        {
          "id": 126,
          "attribute": null,
          "content": "Built and maintained data pipelines ingesting millions of patient and billing records per day.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-12 05:09:43.841545"
        }
      ]
    },
    {
      "id": 33,
      "category": "Problem Solving",
      "observation": "Problem Solving (Medium-High (demonstrates application of problem solving in a relevant context))",
      "confidence": "Medium-High (demonstrates application of problem solving in a relevant context)",
      "created_at": "2026-01-12 05:09:43.841545",
      "evidence": [
        {
          "id": 127,
          "attribute": null,
          "content": "Implemented data quality checks and alerting to catch missing or corrupted healthcare records.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-12 05:09:43.844227"
        }
      ]
    },
    {
      "id": 34,
      "category": "Collaboration",
      "observation": "Collaboration (Medium-High (evidence shows technical collaboration in data pipeline projects, indicating practical teamwork skills))",
      "confidence": "Medium-High (evidence shows technical collaboration in data pipeline projects, indicating practical teamwork skills)",
      "created_at": "2026-01-12 05:09:43.844751",
      "evidence": [
        {
          "id": 128,
          "attribute": null,
          "content": "Built and maintained data pipelines ingesting millions of patient and billing records per day.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-12 05:09:43.848386"
        }
      ]
    },
    {
      "id": 35,
      "category": "Attention to Detail",
      "observation": "Attention to Detail (High (evidence shows practical application in a critical domain, indicating genuine skill))",
      "confidence": "High (evidence shows practical application in a critical domain, indicating genuine skill)",
      "created_at": "2026-01-12 05:09:43.848386",
      "evidence": [
        {
          "id": 129,
          "attribute": null,
          "content": "Implemented data quality checks and alerting to catch missing or corrupted healthcare records.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-12 05:09:43.852262"
        }
      ]
    },
    {
      "id": 36,
      "category": "Technical Ownership",
      "observation": "Technical Ownership (High (specific example demonstrates active management and problem-solving in data pipeline ownership))",
      "confidence": "High (specific example demonstrates active management and problem-solving in data pipeline ownership)",
      "created_at": "2026-01-12 05:09:43.852262",
      "evidence": [
        {
          "id": 130,
          "attribute": null,
          "content": "I was responsible for keeping data pipelines within SLA. I investigated failures, fixed broken jobs, and added alerts when data freshness dropped.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:18:40.564871",
          "created_at": "2026-01-12 05:09:43.855631"
        }
      ]
    },
    {
      "id": 37,
      "category": "Impact Focus",
      "observation": "Impact Focus (High (specific example demonstrates a tangible impact and understanding of impact focus in a healthcare setting))",
      "confidence": "High (specific example demonstrates a tangible impact and understanding of impact focus in a healthcare setting)",
      "created_at": "2026-01-12 05:09:43.855631",
      "evidence": [
        {
          "id": 131,
          "attribute": null,
          "content": "We cut reporting delays from days to hours and reduced data errors by over 50%, which improved hospital billing accuracy.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:20:40.564871",
          "created_at": "2026-01-12 05:09:43.859916"
        }
      ]
    },
    {
      "id": 38,
      "category": "Trade-off Decision-Making",
      "observation": "Trade-off Decision-Making (High (specific example demonstrates understanding of trade-offs in decision-making processes))",
      "confidence": "High (specific example demonstrates understanding of trade-offs in decision-making processes)",
      "created_at": "2026-01-12 05:09:43.860438",
      "evidence": [
        {
          "id": 132,
          "attribute": null,
          "content": "We chose slower but more reliable batch processing for critical compliance reports instead of real-time pipelines, because accuracy mattered more than speed.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:21:40.564871",
          "created_at": "2026-01-12 05:09:43.863710"
        }
      ]
    },
    {
      "id": 39,
      "category": "Operational Responsibility",
      "observation": "Operational Responsibility (Medium-High (evidence shows practical experience managing operational tasks, but not necessarily deep technical expertise))",
      "confidence": "Medium-High (evidence shows practical experience managing operational tasks, but not necessarily deep technical expertise)",
      "created_at": "2026-01-12 05:09:43.863710",
      "evidence": [
        {
          "id": 133,
          "attribute": null,
          "content": "Yes  I was responsible for keeping data pipelines within SLA. I investigated failures, fixed broken jobs, and added alerts when data freshness dropped.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:18:40.564871",
          "created_at": "2026-01-12 05:09:43.867525"
        }
      ]
    },
    {
      "id": 40,
      "category": "Technical Leadership",
      "observation": "Technical Leadership (High (specific example demonstrates leadership in a complex, relevant project))",
      "confidence": "High (specific example demonstrates leadership in a complex, relevant project)",
      "created_at": "2026-01-13 01:04:57.220148",
      "evidence": [
        {
          "id": 153,
          "attribute": null,
          "content": "Led a migration from on-premise data warehouse to Snowflake, improving query performance and reducing infrastructure costs.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 01:04:57.230361"
        }
      ]
    },
    {
      "id": 41,
      "category": "Autonomy",
      "observation": "Autonomy (Medium-High (demonstrates independent management of complex data pipelines, indicating strong autonomy skills))",
      "confidence": "Medium-High (demonstrates independent management of complex data pipelines, indicating strong autonomy skills)",
      "created_at": "2026-01-13 01:04:57.231107",
      "evidence": [
        {
          "id": 154,
          "attribute": null,
          "content": "Built and maintained data pipelines ingesting millions of patient and billing records per day.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 01:04:57.239013"
        }
      ]
    },
    {
      "id": 42,
      "category": "Problem Solving",
      "observation": "Problem Solving (High (demonstrates practical application in a relevant domain))",
      "confidence": "High (demonstrates practical application in a relevant domain)",
      "created_at": "2026-01-13 01:04:57.239013",
      "evidence": [
        {
          "id": 155,
          "attribute": null,
          "content": "Implemented data quality checks and alerting to catch missing or corrupted healthcare records.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 01:04:57.243619"
        }
      ]
    },
    {
      "id": 43,
      "category": "Attention to Detail",
      "observation": "Attention to Detail (High (demonstrates ability to ensure data quality and reliability, essential in IT roles involving data management and reporting))",
      "confidence": "High (demonstrates ability to ensure data quality and reliability, essential in IT roles involving data management and reporting)",
      "created_at": "2026-01-13 01:04:57.243619",
      "evidence": [
        {
          "id": 156,
          "attribute": null,
          "content": "Supported nightly reporting deadlines for hospitals and was monitored for data freshness, pipeline failures, and SLA breaches.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 01:04:57.250990"
        }
      ]
    },
    {
      "id": 44,
      "category": "Responsibility for Mission-Critical Systems",
      "observation": "Responsibility for Mission-Critical Systems (High (specific example demonstrates understanding beyond surface level))",
      "confidence": "High (specific example demonstrates understanding beyond surface level)",
      "created_at": "2026-01-13 01:04:57.251438",
      "evidence": [
        {
          "id": 157,
          "attribute": null,
          "content": "They were mission critical. If our pipelines failed, hospitals couldnt submit reports or get reimbursed properly, which directly impacted revenue.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:16:40",
          "created_at": "2026-01-13 01:04:57.256216"
        }
      ]
    },
    {
      "id": 45,
      "category": "Operational Management",
      "observation": "Operational Management (Medium-High (clear evidence of operational management skills demonstrated through specific responsibilities))",
      "confidence": "Medium-High (clear evidence of operational management skills demonstrated through specific responsibilities)",
      "created_at": "2026-01-13 01:04:57.256216",
      "evidence": [
        {
          "id": 158,
          "attribute": null,
          "content": "Yes  I was responsible for keeping data pipelines within SLA. I investigated failures, fixed broken jobs, and added alerts when data freshness dropped.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:18:40",
          "created_at": "2026-01-13 01:04:57.261906"
        }
      ]
    },
    {
      "id": 46,
      "category": "Impact-Driven Delivery",
      "observation": "Impact-Driven Delivery (High (specific example demonstrates tangible impact and understanding of impact-driven delivery))",
      "confidence": "High (specific example demonstrates tangible impact and understanding of impact-driven delivery)",
      "created_at": "2026-01-13 01:04:57.262438",
      "evidence": [
        {
          "id": 159,
          "attribute": null,
          "content": "We cut reporting delays from days to hours and reduced data errors by over 50%, which improved hospital billing accuracy.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:20:40",
          "created_at": "2026-01-13 01:04:57.268044"
        }
      ]
    },
    {
      "id": 47,
      "category": "Decision-Making and Trade-offs",
      "observation": "Decision-Making and Trade-offs (High (specific example demonstrates understanding of prioritizing reliability over speed in critical processes))",
      "confidence": "High (specific example demonstrates understanding of prioritizing reliability over speed in critical processes)",
      "created_at": "2026-01-13 01:04:57.268044",
      "evidence": [
        {
          "id": 160,
          "attribute": null,
          "content": "We chose slower but more reliable batch processing for critical compliance reports instead of real-time pipelines, because accuracy mattered more than speed.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:21:40",
          "created_at": "2026-01-13 01:04:57.273658"
        }
      ]
    },
    {
      "id": 48,
      "category": "Technical Leadership",
      "observation": "Technical Leadership (High (multiple concrete examples demonstrate leadership in complex technical projects))",
      "confidence": "High (multiple concrete examples demonstrate leadership in complex technical projects)",
      "created_at": "2026-01-13 03:43:29.236375",
      "evidence": [
        {
          "id": 170,
          "attribute": null,
          "content": "My team built and ran the data platform that hospitals used to analyze patient, billing, and operational data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:15:40",
          "created_at": "2026-01-13 03:43:29.247609"
        },
        {
          "id": 169,
          "attribute": null,
          "content": "Led a migration from on-premise data warehouse to Snowflake, improving query performance and reducing infrastructure costs.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 03:43:29.247609"
        }
      ]
    },
    {
      "id": 49,
      "category": "Autonomy",
      "observation": "Autonomy (High (clear evidence of independent work in complex data engineering tasks))",
      "confidence": "High (clear evidence of independent work in complex data engineering tasks)",
      "created_at": "2026-01-13 03:43:29.247609",
      "evidence": [
        {
          "id": 171,
          "attribute": null,
          "content": "Built and maintained data pipelines ingesting millions of patient and billing records per day.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 03:43:29.251351"
        }
      ]
    },
    {
      "id": 50,
      "category": "Attention to Detail",
      "observation": "Attention to Detail (Medium-High (evidence suggests practical application in data quality, a common IT concern))",
      "confidence": "Medium-High (evidence suggests practical application in data quality, a common IT concern)",
      "created_at": "2026-01-13 03:43:29.251351",
      "evidence": [
        {
          "id": 172,
          "attribute": null,
          "content": "Implemented data quality checks and alerting to catch missing or corrupted healthcare records.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 03:43:29.253882"
        }
      ]
    },
    {
      "id": 51,
      "category": "Operational Focus",
      "observation": "Operational Focus (High (specific example demonstrates understanding of operational monitoring and data quality management))",
      "confidence": "High (specific example demonstrates understanding of operational monitoring and data quality management)",
      "created_at": "2026-01-13 03:43:29.253882",
      "evidence": [
        {
          "id": 173,
          "attribute": null,
          "content": "The platform supported nightly reporting deadlines for hospitals and was monitored for data freshness, pipeline failures, and SLA breaches.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 03:43:29.256498"
        }
      ]
    },
    {
      "id": 52,
      "category": "Operational Responsibility",
      "observation": "Operational Responsibility (High (specific example demonstrates hands-on experience managing and maintaining operational systems))",
      "confidence": "High (specific example demonstrates hands-on experience managing and maintaining operational systems)",
      "created_at": "2026-01-13 03:43:29.257021",
      "evidence": [
        {
          "id": 174,
          "attribute": null,
          "content": "Yes  I was responsible for keeping data pipelines within SLA. I investigated failures, fixed broken jobs, and added alerts when data freshness dropped.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:18:40",
          "created_at": "2026-01-13 03:43:29.260098"
        }
      ]
    },
    {
      "id": 53,
      "category": "Impact Orientation",
      "observation": "Impact Orientation (High (specific example shows measurable impact and understanding of process improvements))",
      "confidence": "High (specific example shows measurable impact and understanding of process improvements)",
      "created_at": "2026-01-13 03:43:29.260098",
      "evidence": [
        {
          "id": 175,
          "attribute": null,
          "content": "We cut reporting delays from days to hours and reduced data errors by over 50%, which improved hospital billing accuracy.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:20:40",
          "created_at": "2026-01-13 03:43:29.265158"
        }
      ]
    },
    {
      "id": 54,
      "category": "Technical Leadership",
      "observation": "Technical Leadership (High (multiple concrete examples demonstrate leadership in technical projects))",
      "confidence": "High (multiple concrete examples demonstrate leadership in technical projects)",
      "created_at": "2026-01-13 04:10:16.203484",
      "evidence": [
        {
          "id": 196,
          "attribute": null,
          "content": "My team built and ran the data platform that hospitals used to analyze patient, billing, and operational data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:15:40",
          "created_at": "2026-01-13 04:10:16.211074"
        },
        {
          "id": 195,
          "attribute": null,
          "content": "Led a migration from on-premise data warehouse to Snowflake, improving query performance and reducing infrastructure costs.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:10:16.211074"
        }
      ]
    },
    {
      "id": 55,
      "category": "Autonomy",
      "observation": "Autonomy (Medium-High (evidence suggests ability to work independently on complex data tasks, but context of autonomy as a soft skill is limited))",
      "confidence": "Medium-High (evidence suggests ability to work independently on complex data tasks, but context of autonomy as a soft skill is limited)",
      "created_at": "2026-01-13 04:10:16.211074",
      "evidence": [
        {
          "id": 197,
          "attribute": null,
          "content": "Built and maintained data pipelines ingesting millions of patient and billing records per day.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:10:16.213747"
        }
      ]
    },
    {
      "id": 56,
      "category": "Problem Solving",
      "observation": "Problem Solving (High (specific example demonstrates practical application of problem solving in data quality context))",
      "confidence": "High (specific example demonstrates practical application of problem solving in data quality context)",
      "created_at": "2026-01-13 04:10:16.214274",
      "evidence": [
        {
          "id": 198,
          "attribute": null,
          "content": "Implemented data quality checks and alerting to catch missing or corrupted healthcare records.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:10:16.216898"
        }
      ]
    },
    {
      "id": 57,
      "category": "Collaboration",
      "observation": "Collaboration (Medium-High (evidence shows collaboration in cross-functional projects, indicating genuine teamwork skills))",
      "confidence": "Medium-High (evidence shows collaboration in cross-functional projects, indicating genuine teamwork skills)",
      "created_at": "2026-01-13 04:10:16.216898",
      "evidence": [
        {
          "id": 199,
          "attribute": null,
          "content": "Developed compliance reporting pipelines for hospital finance teams.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:10:16.221248"
        },
        {
          "id": 200,
          "attribute": null,
          "content": "Analytics dashboards used by executives to track operational efficiency and reimbursement rates.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:10:16.221248"
        }
      ]
    },
    {
      "id": 58,
      "category": "Operational Responsibility",
      "observation": "Operational Responsibility (High (specific example demonstrates hands-on operational experience and understanding of data pipeline management))",
      "confidence": "High (specific example demonstrates hands-on operational experience and understanding of data pipeline management)",
      "created_at": "2026-01-13 04:10:16.221248",
      "evidence": [
        {
          "id": 201,
          "attribute": null,
          "content": "Yes  I was responsible for keeping data pipelines within SLA. I investigated failures, fixed broken jobs, and added alerts when data freshness dropped.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:18:40",
          "created_at": "2026-01-13 04:10:16.225650"
        }
      ]
    },
    {
      "id": 59,
      "category": "Impact Orientation",
      "observation": "Impact Orientation (High (specific example demonstrates a clear impact on operational efficiency and accuracy))",
      "confidence": "High (specific example demonstrates a clear impact on operational efficiency and accuracy)",
      "created_at": "2026-01-13 04:10:16.225650",
      "evidence": [
        {
          "id": 202,
          "attribute": null,
          "content": "We cut reporting delays from days to hours and reduced data errors by over 50%, which improved hospital billing accuracy.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:20:40",
          "created_at": "2026-01-13 04:10:16.230280"
        }
      ]
    },
    {
      "id": 60,
      "category": "Decision Making",
      "observation": "Decision Making (High (specific example demonstrates applied decision making in critical situations))",
      "confidence": "High (specific example demonstrates applied decision making in critical situations)",
      "created_at": "2026-01-13 04:10:16.230280",
      "evidence": [
        {
          "id": 203,
          "attribute": null,
          "content": "We chose slower but more reliable batch processing for critical compliance reports instead of real-time pipelines, because accuracy mattered more than speed.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:21:40",
          "created_at": "2026-01-13 04:10:16.233744"
        }
      ]
    },
    {
      "id": 61,
      "category": "Technical Leadership",
      "observation": "Technical Leadership (High (specific examples demonstrate practical leadership in complex projects))",
      "confidence": "High (specific examples demonstrate practical leadership in complex projects)",
      "created_at": "2026-01-13 04:57:01.272583",
      "evidence": [
        {
          "id": 223,
          "attribute": null,
          "content": "Led a migration from on-premise data warehouse to Snowflake, improving query performance and reducing infrastructure costs.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:57:01.282949"
        },
        {
          "id": 224,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes. Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:17:40.564871",
          "created_at": "2026-01-13 04:57:01.282949"
        }
      ]
    },
    {
      "id": 62,
      "category": "Problem Solving",
      "observation": "Problem Solving (High (demonstrates practical application in a relevant context))",
      "confidence": "High (demonstrates practical application in a relevant context)",
      "created_at": "2026-01-13 04:57:01.282949",
      "evidence": [
        {
          "id": 225,
          "attribute": null,
          "content": "Implemented data quality checks and alerting to catch missing or corrupted healthcare records.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:57:01.287731"
        }
      ]
    },
    {
      "id": 63,
      "category": "Autonomy",
      "observation": "Autonomy (Medium-High (demonstrates independent responsibility in managing complex data pipelines, indicating strong autonomy skills))",
      "confidence": "Medium-High (demonstrates independent responsibility in managing complex data pipelines, indicating strong autonomy skills)",
      "created_at": "2026-01-13 04:57:01.288273",
      "evidence": [
        {
          "id": 226,
          "attribute": null,
          "content": "Built and maintained data pipelines ingesting millions of patient and billing records per day.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:57:01.292985"
        }
      ]
    },
    {
      "id": 64,
      "category": "Collaboration",
      "observation": "Collaboration (Medium-High (experience indicates practical application of collaboration skills in complex, multi-stakeholder environments))",
      "confidence": "Medium-High (experience indicates practical application of collaboration skills in complex, multi-stakeholder environments)",
      "created_at": "2026-01-13 04:57:01.292985",
      "evidence": [
        {
          "id": 227,
          "attribute": null,
          "content": "Worked on healthcare analytics platforms used by hospitals and insurance providers.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:57:01.297837"
        }
      ]
    },
    {
      "id": 65,
      "category": "Communication Skills",
      "observation": "Communication Skills (Medium-High (evidence suggests the candidate can interpret and communicate data insights to executives))",
      "confidence": "Medium-High (evidence suggests the candidate can interpret and communicate data insights to executives)",
      "created_at": "2026-01-13 04:57:01.298384",
      "evidence": [
        {
          "id": 228,
          "attribute": null,
          "content": "Analytics dashboards used by executives to track operational efficiency and reimbursement rates.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 04:57:01.302771"
        }
      ]
    },
    {
      "id": 66,
      "category": "Operational Responsibility",
      "observation": "Operational Responsibility (High (specific example demonstrates practical operational skills and understanding of data pipeline management))",
      "confidence": "High (specific example demonstrates practical operational skills and understanding of data pipeline management)",
      "created_at": "2026-01-13 04:57:01.303312",
      "evidence": [
        {
          "id": 229,
          "attribute": null,
          "content": "Yes  I was responsible for keeping data pipelines within SLA. I investigated failures, fixed broken jobs, and added alerts when data freshness dropped.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:18:40.564871",
          "created_at": "2026-01-13 04:57:01.307993"
        }
      ]
    },
    {
      "id": 67,
      "category": "Impact Orientation",
      "observation": "Impact Orientation (High (specific example demonstrates clear impact on operational efficiency and accuracy))",
      "confidence": "High (specific example demonstrates clear impact on operational efficiency and accuracy)",
      "created_at": "2026-01-13 04:57:01.307993",
      "evidence": [
        {
          "id": 230,
          "attribute": null,
          "content": "We cut reporting delays from days to hours and reduced data errors by over 50%, which improved hospital billing accuracy.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:20:40.564871",
          "created_at": "2026-01-13 04:57:01.312954"
        }
      ]
    },
    {
      "id": 68,
      "category": "Decision-Making",
      "observation": "Decision-Making (High (specific decision-making example shows understanding of trade-offs and prioritization in critical tasks))",
      "confidence": "High (specific decision-making example shows understanding of trade-offs and prioritization in critical tasks)",
      "created_at": "2026-01-13 04:57:01.312954",
      "evidence": [
        {
          "id": 231,
          "attribute": null,
          "content": "We chose slower but more reliable batch processing for critical compliance reports instead of real-time pipelines, because accuracy mattered more than speed.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:21:40.564871",
          "created_at": "2026-01-13 04:57:01.317180"
        }
      ]
    },
    {
      "id": 69,
      "category": "Technical Leadership",
      "observation": "Technical Leadership (High (multiple specific examples demonstrate leadership in complex technical projects))",
      "confidence": "High (multiple specific examples demonstrate leadership in complex technical projects)",
      "created_at": "2026-01-13 05:09:53.757419",
      "evidence": [
        {
          "id": 252,
          "attribute": null,
          "content": "We ran Airflow and Spark jobs in Kubernetes. Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:17:40",
          "created_at": "2026-01-13 05:09:53.767914"
        },
        {
          "id": 251,
          "attribute": null,
          "content": "Led a migration from on-premise data warehouse to Snowflake, improving query performance and reducing infrastructure costs.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 05:09:53.767914"
        }
      ]
    },
    {
      "id": 70,
      "category": "Autonomy",
      "observation": "Autonomy (Medium-High (specific example indicates independent handling of complex data workflows))",
      "confidence": "Medium-High (specific example indicates independent handling of complex data workflows)",
      "created_at": "2026-01-13 05:09:53.767914",
      "evidence": [
        {
          "id": 253,
          "attribute": null,
          "content": "Built and maintained data pipelines ingesting millions of patient and billing records per day.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 05:09:53.773399"
        }
      ]
    },
    {
      "id": 71,
      "category": "Attention to Detail",
      "observation": "Attention to Detail (High (specific example demonstrates application of attention to detail in critical healthcare data context))",
      "confidence": "High (specific example demonstrates application of attention to detail in critical healthcare data context)",
      "created_at": "2026-01-13 05:09:53.773399",
      "evidence": [
        {
          "id": 254,
          "attribute": null,
          "content": "Implemented data quality checks and alerting to catch missing or corrupted healthcare records.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 05:09:53.778075"
        }
      ]
    },
    {
      "id": 72,
      "category": "Process Orientation",
      "observation": "Process Orientation (Medium-High (clear evidence of monitoring process performance in a healthcare setting, indicating practical understanding))",
      "confidence": "Medium-High (clear evidence of monitoring process performance in a healthcare setting, indicating practical understanding)",
      "created_at": "2026-01-13 05:09:53.778668",
      "evidence": [
        {
          "id": 255,
          "attribute": null,
          "content": "The platform supported nightly reporting deadlines for hospitals and was monitored for data freshness, pipeline failures, and SLA breaches.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-13 05:09:53.783536"
        }
      ]
    },
    {
      "id": 73,
      "category": "Operational Responsibility",
      "observation": "Operational Responsibility (Medium-High (evidence of hands-on operational tasks demonstrates genuine responsibility))",
      "confidence": "Medium-High (evidence of hands-on operational tasks demonstrates genuine responsibility)",
      "created_at": "2026-01-13 05:09:53.783536",
      "evidence": [
        {
          "id": 256,
          "attribute": null,
          "content": "Yes  I was responsible for keeping data pipelines within SLA. I investigated failures, fixed broken jobs, and added alerts when data freshness dropped.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:18:40",
          "created_at": "2026-01-13 05:09:53.787577"
        }
      ]
    },
    {
      "id": 74,
      "category": "Impact Orientation",
      "observation": "Impact Orientation (High (specific achievement related to impact orientation demonstrates a clear understanding and application of the skill))",
      "confidence": "High (specific achievement related to impact orientation demonstrates a clear understanding and application of the skill)",
      "created_at": "2026-01-13 05:09:53.788047",
      "evidence": [
        {
          "id": 257,
          "attribute": null,
          "content": "We cut reporting delays from days to hours and reduced data errors by over 50%, which improved hospital billing accuracy.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:20:40",
          "created_at": "2026-01-13 05:09:53.792652"
        }
      ]
    },
    {
      "id": 75,
      "category": "Decision Making",
      "observation": "Decision Making (High (specific example demonstrates thoughtful decision-making in a critical context))",
      "confidence": "High (specific example demonstrates thoughtful decision-making in a critical context)",
      "created_at": "2026-01-13 05:09:53.792652",
      "evidence": [
        {
          "id": 258,
          "attribute": null,
          "content": "We chose slower but more reliable batch processing for critical compliance reports instead of real-time pipelines, because accuracy mattered more than speed.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:21:40",
          "created_at": "2026-01-13 05:09:53.796028"
        }
      ]
    },
    {
      "id": 76,
      "category": "Technical Leadership",
      "observation": "Technical Leadership (High (specific examples demonstrate leadership in critical technical projects and team management))",
      "confidence": "High (specific examples demonstrate leadership in critical technical projects and team management)",
      "created_at": "2026-01-14 21:57:39.380440",
      "evidence": [
        {
          "id": 277,
          "attribute": null,
          "content": "Led a migration from on-premise data warehouse to Snowflake, improving query performance and reducing infrastructure costs.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-14 21:57:39.388353"
        },
        {
          "id": 278,
          "attribute": null,
          "content": "My team built and ran the data platform that hospitals used to analyze patient, billing, and operational data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:15:40",
          "created_at": "2026-01-14 21:57:39.388353"
        }
      ]
    },
    {
      "id": 77,
      "category": "Autonomy",
      "observation": "Autonomy (Medium-High (demonstrates ability to work independently on large-scale data projects))",
      "confidence": "Medium-High (demonstrates ability to work independently on large-scale data projects)",
      "created_at": "2026-01-14 21:57:39.388353",
      "evidence": [
        {
          "id": 279,
          "attribute": null,
          "content": "Built and maintained data pipelines ingesting millions of patient and billing records per day.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-14 21:57:39.391484"
        }
      ]
    },
    {
      "id": 78,
      "category": "Problem Solving",
      "observation": "Problem Solving (High (specific example shows practical application of problem solving in a critical domain))",
      "confidence": "High (specific example shows practical application of problem solving in a critical domain)",
      "created_at": "2026-01-14 21:57:39.391484",
      "evidence": [
        {
          "id": 280,
          "attribute": null,
          "content": "Implemented data quality checks and alerting to catch missing or corrupted healthcare records.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-14 21:57:39.394122"
        }
      ]
    },
    {
      "id": 79,
      "category": "Communication",
      "observation": "Communication (Medium (general mention of dashboards suggests some communication skills, but lacks detail on the candidate's direct communication abilities))",
      "confidence": "Medium (general mention of dashboards suggests some communication skills, but lacks detail on the candidate's direct communication abilities)",
      "created_at": "2026-01-14 21:57:39.394122",
      "evidence": [
        {
          "id": 281,
          "attribute": null,
          "content": "Analytics dashboards used by executives to track operational efficiency and reimbursement rates.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-14 21:57:39.396757"
        }
      ]
    },
    {
      "id": 80,
      "category": "Responsibility",
      "observation": "Responsibility (Medium-High (clear evidence of responsibility in data pipeline management indicates genuine skill))",
      "confidence": "Medium-High (clear evidence of responsibility in data pipeline management indicates genuine skill)",
      "created_at": "2026-01-14 21:57:39.396757",
      "evidence": [
        {
          "id": 282,
          "attribute": null,
          "content": "Yes  I was responsible for keeping data pipelines within SLA. I investigated failures, fixed broken jobs, and added alerts when data freshness dropped.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:18:40",
          "created_at": "2026-01-14 21:57:39.399313"
        }
      ]
    },
    {
      "id": 81,
      "category": "Operational Awareness",
      "observation": "Operational Awareness (Medium-High (specific examples show practical application in operational roles))",
      "confidence": "Medium-High (specific examples show practical application in operational roles)",
      "created_at": "2026-01-14 21:57:39.399840",
      "evidence": [
        {
          "id": 283,
          "attribute": null,
          "content": "I investigated failures, fixed broken jobs, and added alerts when data freshness dropped.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:18:40",
          "created_at": "2026-01-14 21:57:39.401990"
        }
      ]
    },
    {
      "id": 82,
      "category": "Impact Orientation",
      "observation": "Impact Orientation (High (specific example demonstrates measurable impact and understanding of impact orientation in a healthcare setting))",
      "confidence": "High (specific example demonstrates measurable impact and understanding of impact orientation in a healthcare setting)",
      "created_at": "2026-01-14 21:57:39.401990",
      "evidence": [
        {
          "id": 284,
          "attribute": null,
          "content": "We cut reporting delays from days to hours and reduced data errors by over 50%, which improved hospital billing accuracy.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:20:40",
          "created_at": "2026-01-14 21:57:39.404089"
        }
      ]
    },
    {
      "id": 83,
      "category": "Decision-Making",
      "observation": "Decision-Making (Medium (mentions usage but limited depth))",
      "confidence": "Medium (mentions usage but limited depth)",
      "created_at": "2026-01-14 21:57:39.404626",
      "evidence": [
        {
          "id": 285,
          "attribute": null,
          "content": "We chose slower but more reliable batch processing for critical compliance reports instead of real-time pipelines, because accuracy mattered more than speed.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:21:40",
          "created_at": "2026-01-14 21:57:39.406728"
        }
      ]
    },
    {
      "id": 84,
      "category": "Technical Leadership",
      "observation": "Technical Leadership (High (specific examples demonstrate leadership in technical projects and team management))",
      "confidence": "High (specific examples demonstrate leadership in technical projects and team management)",
      "created_at": "2026-01-19 06:10:44.444170",
      "evidence": [
        {
          "id": 306,
          "attribute": null,
          "content": "Led a migration from on-premise data warehouse to Snowflake, improving query performance and reducing infrastructure costs.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 06:10:44.454708"
        },
        {
          "id": 307,
          "attribute": null,
          "content": "My team built and ran the data platform that hospitals used to analyze patient, billing, and operational data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:15:40",
          "created_at": "2026-01-19 06:10:44.454708"
        }
      ]
    },
    {
      "id": 85,
      "category": "Autonomy",
      "observation": "Autonomy (Medium-High (the evidence suggests independent work, but the skill's relevance depends on context))",
      "confidence": "Medium-High (the evidence suggests independent work, but the skill's relevance depends on context)",
      "created_at": "2026-01-19 06:10:44.455245",
      "evidence": [
        {
          "id": 308,
          "attribute": null,
          "content": "Built and maintained data pipelines ingesting millions of patient and billing records per day.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 06:10:44.460619"
        }
      ]
    },
    {
      "id": 86,
      "category": "Attention to Detail",
      "observation": "Attention to Detail (High (specific example demonstrates practical application in a critical domain))",
      "confidence": "High (specific example demonstrates practical application in a critical domain)",
      "created_at": "2026-01-19 06:10:44.460619",
      "evidence": [
        {
          "id": 309,
          "attribute": null,
          "content": "Implemented data quality checks and alerting to catch missing or corrupted healthcare records.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 06:10:44.464798"
        }
      ]
    },
    {
      "id": 87,
      "category": "Problem-solving",
      "observation": "Problem-solving (Medium-High (demonstrates practical application in a complex data environment))",
      "confidence": "Medium-High (demonstrates practical application in a complex data environment)",
      "created_at": "2026-01-19 06:10:44.464798",
      "evidence": [
        {
          "id": 310,
          "attribute": null,
          "content": "Built and maintained data pipelines ingesting millions of patient and billing records per day.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 06:10:44.468550"
        }
      ]
    },
    {
      "id": 88,
      "category": "Communication",
      "observation": "Communication (Medium-High (indirect evidence suggests understanding of communication, but no direct evidence of skill))",
      "confidence": "Medium-High (indirect evidence suggests understanding of communication, but no direct evidence of skill)",
      "created_at": "2026-01-19 06:10:44.468550",
      "evidence": [
        {
          "id": 311,
          "attribute": null,
          "content": "Analytics dashboards used by executives to track operational efficiency and reimbursement rates.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 06:10:44.471730"
        }
      ]
    },
    {
      "id": 89,
      "category": "Operational Responsibility",
      "observation": "Operational Responsibility (Medium-High (clear example of operational responsibility in maintaining data pipelines demonstrates relevant experience))",
      "confidence": "Medium-High (clear example of operational responsibility in maintaining data pipelines demonstrates relevant experience)",
      "created_at": "2026-01-19 06:10:44.472262",
      "evidence": [
        {
          "id": 312,
          "attribute": null,
          "content": "I was responsible for keeping data pipelines within SLA. I investigated failures, fixed broken jobs, and added alerts when data freshness dropped.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:18:40",
          "created_at": "2026-01-19 06:10:44.475128"
        }
      ]
    },
    {
      "id": 90,
      "category": "Impact Orientation",
      "observation": "Impact Orientation (High (specific example demonstrates measurable impact on processes and accuracy))",
      "confidence": "High (specific example demonstrates measurable impact on processes and accuracy)",
      "created_at": "2026-01-19 06:10:44.475128",
      "evidence": [
        {
          "id": 313,
          "attribute": null,
          "content": "We cut reporting delays from days to hours and reduced data errors by over 50%, which improved hospital billing accuracy.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:20:40",
          "created_at": "2026-01-19 06:10:44.478629"
        }
      ]
    },
    {
      "id": 91,
      "category": "Decision-Making",
      "observation": "Decision-Making (High (specific example demonstrates understanding beyond surface level))",
      "confidence": "High (specific example demonstrates understanding beyond surface level)",
      "created_at": "2026-01-19 06:10:44.478629",
      "evidence": [
        {
          "id": 314,
          "attribute": null,
          "content": "We chose slower but more reliable batch processing for critical compliance reports instead of real-time pipelines, because accuracy mattered more than speed.",
          "source_type": "conversation",
          "source_reference": "2026-01-12 01:21:40",
          "created_at": "2026-01-19 06:10:44.481812"
        }
      ]
    },
    {
      "id": 92,
      "category": "Technical Leadership",
      "observation": "Technical Leadership (High (specific examples demonstrate deep understanding and practical application of technical leadership in data engineering projects))",
      "confidence": "High (specific examples demonstrate deep understanding and practical application of technical leadership in data engineering projects)",
      "created_at": "2026-01-19 07:42:44.828815",
      "evidence": [
        {
          "id": 336,
          "attribute": null,
          "content": "Led a migration from on-premise data warehouse to Snowflake, improving query performance and reducing infrastructure costs.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 07:42:44.833509"
        },
        {
          "id": 337,
          "attribute": null,
          "content": "We designed batch and streaming pipelines using Spark and Airflow, and built data models with dbt so analysts could trust the data.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:19:40.564871",
          "created_at": "2026-01-19 07:42:44.833509"
        }
      ]
    },
    {
      "id": 93,
      "category": "Autonomy",
      "observation": "Autonomy (Medium-High (evidence of managing complex data pipelines suggests strong autonomous working capability))",
      "confidence": "Medium-High (evidence of managing complex data pipelines suggests strong autonomous working capability)",
      "created_at": "2026-01-19 07:42:44.833509",
      "evidence": [
        {
          "id": 338,
          "attribute": null,
          "content": "Built and maintained data pipelines ingesting millions of patient and billing records per day.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 07:42:44.837214"
        }
      ]
    },
    {
      "id": 94,
      "category": "Problem Solving",
      "observation": "Problem Solving (High (specific example demonstrates applied problem solving in a critical domain))",
      "confidence": "High (specific example demonstrates applied problem solving in a critical domain)",
      "created_at": "2026-01-19 07:42:44.837214",
      "evidence": [
        {
          "id": 339,
          "attribute": null,
          "content": "Implemented data quality checks and alerting to catch missing or corrupted healthcare records.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 07:42:44.839316"
        }
      ]
    },
    {
      "id": 95,
      "category": "Collaboration",
      "observation": "Collaboration (Medium-High (evidence suggests practical experience in collaborative healthcare projects))",
      "confidence": "Medium-High (evidence suggests practical experience in collaborative healthcare projects)",
      "created_at": "2026-01-19 07:42:44.839316",
      "evidence": [
        {
          "id": 340,
          "attribute": null,
          "content": "Worked on healthcare analytics platforms used by hospitals and insurance providers.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 07:42:44.841590"
        }
      ]
    },
    {
      "id": 96,
      "category": "Result Orientation",
      "observation": "Result Orientation (High (specific example demonstrates a clear understanding of monitoring and ensuring timely reporting, which is relevant in IT roles))",
      "confidence": "High (specific example demonstrates a clear understanding of monitoring and ensuring timely reporting, which is relevant in IT roles)",
      "created_at": "2026-01-19 07:42:44.841590",
      "evidence": [
        {
          "id": 341,
          "attribute": null,
          "content": "Supported nightly reporting deadlines for hospitals and was monitored for data freshness, pipeline failures, and SLA breaches.",
          "source_type": "resume",
          "source_reference": "",
          "created_at": "2026-01-19 07:42:44.843712"
        }
      ]
    },
    {
      "id": 97,
      "category": "Operational Responsibility",
      "observation": "Operational Responsibility (High (specific examples demonstrate practical understanding and application in operational roles))",
      "confidence": "High (specific examples demonstrate practical understanding and application in operational roles)",
      "created_at": "2026-01-19 07:42:44.843712",
      "evidence": [
        {
          "id": 342,
          "attribute": null,
          "content": "I was responsible for keeping data pipelines within SLA. I investigated failures, fixed broken jobs, and added alerts when data freshness dropped.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:18:40.564871",
          "created_at": "2026-01-19 07:42:44.845274"
        },
        {
          "id": 343,
          "attribute": null,
          "content": "Yes  I was responsible for keeping data pipelines within SLA. I investigated failures, fixed broken jobs, and added alerts when data freshness dropped.",
          "source_type": "conversation",
          "source_reference": "2026-01-13T08:10:09.18286",
          "created_at": "2026-01-19 07:42:44.845801"
        }
      ]
    },
    {
      "id": 98,
      "category": "Impact Orientation",
      "observation": "Impact Orientation (High (specific example demonstrates tangible impact and understanding of impact orientation in a healthcare IT context))",
      "confidence": "High (specific example demonstrates tangible impact and understanding of impact orientation in a healthcare IT context)",
      "created_at": "2026-01-19 07:42:44.845801",
      "evidence": [
        {
          "id": 344,
          "attribute": null,
          "content": "We cut reporting delays from days to hours and reduced data errors by over 50%, which improved hospital billing accuracy.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:20:40.564871",
          "created_at": "2026-01-19 07:42:44.847914"
        }
      ]
    },
    {
      "id": 99,
      "category": "Decision Making",
      "observation": "Decision Making (High (specific example demonstrates understanding of trade-offs in critical decision making))",
      "confidence": "High (specific example demonstrates understanding of trade-offs in critical decision making)",
      "created_at": "2026-01-19 07:42:44.848457",
      "evidence": [
        {
          "id": 345,
          "attribute": null,
          "content": "We chose slower but more reliable batch processing for critical compliance reports instead of real-time pipelines, because accuracy mattered more than speed.",
          "source_type": "conversation",
          "source_reference": "2026-01-12T01:21:40.564871",
          "created_at": "2026-01-19 07:42:44.850559"
        }
      ]
    }
  ],
  "aspirations": [],
  "confirmed_gaps": [],
  "constraints": [],
  "followup_flags": [],
  "potential_indicators": [],
  "present_state": null,
  "risk_notes": [],
  "domain_contexts": [
    {
      "industry": "Healthcare",
      "product_type": "Data platform",
      "business_model": "Internal",
      "customer_type": "Hospitals and insurance providers",
      "regulatory_or_compliance_context": "Healthcare",
      "business_criticality": "High",
      "evidence": [
        {
          "quote": "Worked on healthcare analytics platforms used by hospitals and insurance providers. Systems processed patient records, billing data, and operational metrics used for compliance reporting and financial forecasting.",
          "timestamp": "",
          "source": "resume"
        }
      ],
      "confidence": "High"
    },
    {
      "industry": "Healthcare",
      "product_type": "Reporting and analytics pipelines",
      "business_model": "Internal",
      "customer_type": "Hospital finance teams and executives",
      "regulatory_or_compliance_context": "Healthcare",
      "business_criticality": "High",
      "evidence": [
        {
          "quote": "Implemented data quality checks and alerting to catch missing or corrupted healthcare records. Projects included compliance reporting pipelines and operational dashboards used by executives.",
          "timestamp": "",
          "source": "resume"
        }
      ],
      "confidence": "High"
    },
    {
      "industry": "Healthcare",
      "product_type": "Reporting and analytics platform",
      "business_model": "Internal",
      "customer_type": "Hospitals",
      "regulatory_or_compliance_context": "Healthcare",
      "business_criticality": "Revenue-impacting",
      "evidence": [
        {
          "quote": "My team built and ran the data platform that hospitals used to analyze patient, billing, and operational data. These systems supported compliance and financial reporting.",
          "timestamp": "",
          "source": "conversation"
        }
      ],
      "confidence": "High"
    },
    {
      "industry": "Healthcare",
      "product_type": "Data platform",
      "business_model": "Internal",
      "customer_type": "Hospitals and insurance providers",
      "regulatory_or_compliance_context": "Healthcare",
      "business_criticality": "High",
      "evidence": [
        {
          "quote": "Worked on healthcare analytics platforms used by hospitals and insurance providers. Systems processed patient records, billing data, and operational metrics used for compliance reporting and financial forecasting.",
          "timestamp": "",
          "source": "resume"
        }
      ],
      "confidence": "High"
    },
    {
      "industry": "Healthcare",
      "product_type": "Reporting and analytics pipelines",
      "business_model": "Internal",
      "customer_type": "Hospital finance teams and executives",
      "regulatory_or_compliance_context": "Healthcare",
      "business_criticality": "High",
      "evidence": [
        {
          "quote": "Projects included compliance reporting pipelines for hospital finance teams and analytics dashboards used by executives.",
          "timestamp": "",
          "source": "resume"
        }
      ],
      "confidence": "High"
    },
    {
      "industry": "Healthcare",
      "product_type": "Reporting system",
      "business_model": "Internal",
      "customer_type": "Hospitals",
      "regulatory_or_compliance_context": "Healthcare",
      "business_criticality": "Revenue-impacting",
      "evidence": [
        {
          "quote": "My team built and ran the data platform that hospitals used to analyze patient, billing, and operational data. These systems supported compliance and financial reporting.",
          "timestamp": "",
          "source": "conversation"
        }
      ],
      "confidence": "High"
    }
  ],
  "infrastructure_contexts": [
    {
      "environment_type": "Production",
      "scale": "Company-wide",
      "reliability_expectation": "High",
      "operational_constraints": "Nightly reporting deadlines",
      "evidence": [
        {
          "quote": "The platform supported nightly reporting deadlines for hospitals",
          "timestamp": "",
          "source": "resume"
        }
      ],
      "confidence": "High"
    },
    {
      "environment_type": "Production",
      "scale": "Team",
      "reliability_expectation": "High",
      "operational_constraints": "Healthcare compliance",
      "evidence": [
        {
          "quote": "Worked on healthcare analytics platforms used by hospitals and insurance providers",
          "timestamp": "",
          "source": "resume"
        }
      ],
      "confidence": "High"
    },
    {
      "environment_type": "Production",
      "scale": "Company-wide",
      "reliability_expectation": "High",
      "operational_constraints": "Processing millions of records daily",
      "evidence": [
        {
          "quote": "Built and maintained data pipelines ingesting millions of patient and billing records per day",
          "timestamp": "",
          "source": "resume"
        }
      ],
      "confidence": "High"
    },
    {
      "environment_type": "Production",
      "scale": "Company-wide",
      "reliability_expectation": "High",
      "operational_constraints": "Compliance reporting",
      "evidence": [
        {
          "quote": "Implemented data quality checks and alerting to catch missing or corrupted healthcare records",
          "timestamp": "",
          "source": "resume"
        }
      ],
      "confidence": "High"
    },
    {
      "environment_type": "Staging",
      "scale": "Team",
      "reliability_expectation": "Medium",
      "operational_constraints": null,
      "evidence": [
        {
          "quote": "Migrated from on-premise data warehouse to Snowflake",
          "timestamp": "",
          "source": "resume"
        }
      ],
      "confidence": "Medium-High"
    },
    {
      "environment_type": "Production",
      "scale": "Team",
      "reliability_expectation": "Mission-critical",
      "operational_constraints": "Healthcare compliance, Financial reporting",
      "evidence": [
        {
          "quote": "My team built and ran the data platform that hospitals used to analyze patient, billing, and operational data. These systems supported compliance and financial reporting.",
          "timestamp": "",
          "source": "conversation"
        }
      ],
      "confidence": "High"
    },
    {
      "environment_type": "Production",
      "scale": "Team",
      "reliability_expectation": "High",
      "operational_constraints": "Hospital report submission, Revenue impact",
      "evidence": [
        {
          "quote": "They were mission critical. If our pipelines failed, hospitals couldnt submit reports or get reimbursed properly, which directly impacted revenue.",
          "timestamp": "",
          "source": "conversation"
        }
      ],
      "confidence": "High"
    },
    {
      "environment_type": "Production",
      "scale": "Team",
      "reliability_expectation": "High",
      "operational_constraints": "Nightly reporting deadlines, Data accuracy",
      "evidence": [
        {
          "quote": "We ran Airflow and Spark jobs in Kubernetes. Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "timestamp": "",
          "source": "conversation"
        }
      ],
      "confidence": "High"
    },
    {
      "environment_type": "Production",
      "scale": "Team",
      "reliability_expectation": "High",
      "operational_constraints": "SLA adherence, Data freshness monitoring",
      "evidence": [
        {
          "quote": "Yes  I was responsible for keeping data pipelines within SLA. I investigated failures, fixed broken jobs, and added alerts when data freshness dropped.",
          "timestamp": "",
          "source": "conversation"
        }
      ],
      "confidence": "High"
    },
    {
      "environment_type": "Prototype",
      "scale": "Team",
      "reliability_expectation": "Medium",
      "operational_constraints": null,
      "evidence": [
        {
          "quote": "I designed batch and streaming pipelines using Spark and Airflow, and built data models with dbt so analysts could trust the data.",
          "timestamp": "",
          "source": "conversation"
        }
      ],
      "confidence": "Medium-High"
    },
    {
      "environment_type": "Production",
      "scale": "Company-wide",
      "reliability_expectation": "High",
      "operational_constraints": "Nightly reporting deadlines",
      "evidence": [
        {
          "quote": "The platform supported nightly reporting deadlines for hospitals",
          "timestamp": "",
          "source": "resume"
        }
      ],
      "confidence": "High"
    },
    {
      "environment_type": "Production",
      "scale": "Team",
      "reliability_expectation": "High",
      "operational_constraints": "Healthcare compliance",
      "evidence": [
        {
          "quote": "Worked on healthcare analytics platforms used by hospitals and insurance providers",
          "timestamp": "",
          "source": "resume"
        }
      ],
      "confidence": "High"
    },
    {
      "environment_type": "Production",
      "scale": "Company-wide",
      "reliability_expectation": "High",
      "operational_constraints": "Supporting healthcare and regulated industries",
      "evidence": [
        {
          "quote": "building production-grade analytics and data platforms for healthcare and regulated industries",
          "timestamp": "",
          "source": "resume"
        }
      ],
      "confidence": "High"
    },
    {
      "environment_type": "Production",
      "scale": "Team",
      "reliability_expectation": "Mission-critical",
      "operational_constraints": "Healthcare compliance",
      "evidence": [
        {
          "quote": "My team built and ran the data platform that hospitals used to analyze patient, billing, and operational data. These systems supported compliance and financial reporting.",
          "timestamp": "",
          "source": "conversation"
        }
      ],
      "confidence": "High"
    },
    {
      "environment_type": "Production",
      "scale": "Team",
      "reliability_expectation": "Mission-critical",
      "operational_constraints": "Hospitals couldnt submit reports or get reimbursed properly if pipelines failed",
      "evidence": [
        {
          "quote": "They were mission critical. If our pipelines failed, hospitals couldnt submit reports or get reimbursed properly, which directly impacted revenue.",
          "timestamp": "",
          "source": "conversation"
        }
      ],
      "confidence": "High"
    },
    {
      "environment_type": "Production",
      "scale": "Team",
      "reliability_expectation": "High",
      "operational_constraints": "Nightly reporting deadlines, regulated data",
      "evidence": [
        {
          "quote": "We ran Airflow and Spark jobs in Kubernetes. Data was stored in Snowflake and S3, and we used GitHub Actions for deploying pipeline changes.",
          "timestamp": "",
          "source": "conversation"
        }
      ],
      "confidence": "High"
    }
  ]
}