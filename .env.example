# LLM Configuration
LLM_PROVIDER=openrouter
LLM_MODEL=openai/gpt-4o-mini
# Resume analyzer overrides (optional)
RESUME_ANALYZER_PROVIDER=openrouter
RESUME_ANALYZER_MODEL=google/gemini-2.5-flash

# OpenRouter Configuration
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
OPENROUTER_MODEL=openai/gpt-4o-mini

# Google Gemini Configuration
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-pro
GEMINI_MAX_RPM=10

# DeepSeek Configuration
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Other Configuration
USE_LLM_QUEUE=false

# Database Configuration
# For local development (Docker):
DATABASE_URL=postgresql://fabric_user:fabric_password@localhost:5432/fabric_db

# For production (Supabase):
# DATABASE_URL=postgresql://postgres.[PROJECT-REF]:[YOUR-PASSWORD]@aws-0-[REGION].pooler.supabase.com:6543/postgres

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# RAG Configuration
EMBEDDING_MODEL=openai/text-embedding-3-small

# Langfuse Observability (Optional)
LANGFUSE_PUBLIC_KEY=pk-lf-...
LANGFUSE_SECRET_KEY=sk-lf-...
LANGFUSE_HOST=https://cloud.langfuse.com
LANGFUSE_ENABLED=false  # Set to true to enable tracing

# Redis Configuration (for Celery)
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/1
